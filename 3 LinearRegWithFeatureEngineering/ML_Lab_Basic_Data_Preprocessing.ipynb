{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HXP8yk8QOUFs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e225f29-507c-4200-dd78-5a0b9f4e721a",
        "id": "ksd7Lq65a3B_"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/')"
      ],
      "metadata": {
        "id": "H2TFjUyVa7Sx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdWPmGeuOUFv"
      },
      "source": [
        "# Pre-Processing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI6xMiiSOUFw"
      },
      "source": [
        "#### Data preprocessing in Machine Learning is a crucial step that helps enhance the quality of data to promote the extraction of meaningful insights from the data.\n",
        "\n",
        "#### Data preprocessing in Machine Learning refers to the technique of preparing (cleaning and organizing) the raw data to make it suitable for a building and training Machine Learning models.\n",
        "\n",
        "#### In simple words, data preprocessing in Machine Learning is a data mining technique that transforms raw data into an understandable and readable format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR7KnCtaOUFx"
      },
      "source": [
        "# STEPS\n",
        "\n",
        "### Getting the dataset\n",
        "### Importing libraries\n",
        "### Importing datasets\n",
        "### Finding Missing Data\n",
        "### Encoding Categorical Data\n",
        "### Splitting dataset into training and test set\n",
        "### Feature scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHWmN_EbOUFy"
      },
      "source": [
        "##### Pre-processing refers to the transformations applied to our data before feeding it to the algorithm.\n",
        "\n",
        "##### Data Preprocessing is a technique that is used to convert the raw data into a clean data set. In other words, whenever the data is gathered from different sources it is collected in raw format which is not feasible for the analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_aTA8e1OUFy"
      },
      "source": [
        "# Need of Data Preprocessing\n",
        "\n",
        "##### For achieving better results from the applied model in Machine Learning projects the format of the data has to be in a proper manner. Some specified Machine Learning model needs information in a specified format, for example, ***Random Forest algorithm does not support null values,*** therefore to execute random forest algorithm null values have to be managed from the original raw data set.\n",
        "\n",
        "##### Another aspect is that ***data set should be formatted in such a way that more than one Machine Learning and Deep Learning algorithms are executed in one data set, and best out of them is chosen.***\n",
        "\n",
        "##### Another reason why feature scaling is applied is that ***gradient descent converges much faster with feature scaling than without it***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j8wsHUsOUFz"
      },
      "source": [
        "# Preprocessing Techniques\n",
        "\n",
        "\n",
        "\n",
        "### Binarize Data  \n",
        "We can transform our data using a binary threshold. All values above the threshold are marked 1 and all equal to or below are marked as 0.\n",
        "\n",
        "\n",
        "### Feature Scaling:\n",
        "It puts all our features on the same scale. You don’t have to apply feature scaling to the dummy variables. Two techniques:\n",
        "\n",
        "(i) Standardization\n",
        "(ii) Normalization\n",
        "\n",
        "### Standardize Data\n",
        "Standardization of datasets is a common requirement for many machine learning estimators\n",
        "\n",
        "### Normalization\n",
        "Normalization involves adjusting the values in the feature vector so as to measure them on a common scale. Here, the values of a feature vector are adjusted so that they sum up to 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "K48x6FHXOUFz"
      },
      "outputs": [],
      "source": [
        "import sklearn.preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSyX80KDOUF0"
      },
      "source": [
        "# Binarize Data (Make Binary)\n",
        "\n",
        "• We can transform our data using a binary threshold. All values above the threshold are marked 1 and all equal to or below are marked as 0.\n",
        "\n",
        "• This is called binarizing your data or threshold your data. It can be useful when you have probabilities that you want to make crisp values. It is also useful when feature engineering and you want to add new features that indicate something meaningful.\n",
        "\n",
        "• We can create new binary attributes in Python using scikit-learn with the Binarizer class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ulq_y59fOUF0"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import Binarizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4Op9ra4rOUF0",
        "outputId": "40700ef3-680c-43d6-ed34-5c80f7487589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   preg  plas  pres  skin  test  mass   pedi  age            class\n",
              "0     6   148    72    35     0  33.6  0.627   50  tested_positive\n",
              "1     1    85    66    29     0  26.6  0.351   31  tested_negative\n",
              "2     8   183    64     0     0  23.3  0.672   32  tested_positive\n",
              "3     1    89    66    23    94  28.1  0.167   21  tested_negative\n",
              "4     0   137    40    35   168  43.1  2.288   33  tested_positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7113cda6-ad61-421c-a006-956d8761132e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preg</th>\n",
              "      <th>plas</th>\n",
              "      <th>pres</th>\n",
              "      <th>skin</th>\n",
              "      <th>test</th>\n",
              "      <th>mass</th>\n",
              "      <th>pedi</th>\n",
              "      <th>age</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>tested_positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>tested_negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>tested_positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>tested_negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>tested_positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7113cda6-ad61-421c-a006-956d8761132e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7113cda6-ad61-421c-a006-956d8761132e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7113cda6-ad61-421c-a006-956d8761132e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8209b733-2984-4351-a126-8d183ca01f7a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8209b733-2984-4351-a126-8d183ca01f7a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8209b733-2984-4351-a126-8d183ca01f7a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 768,\n  \"fields\": [\n    {\n      \"column\": \"preg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 17,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          6,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"plas\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 0,\n        \"max\": 199,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          151,\n          101,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pres\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 122,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          86,\n          46,\n          85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          7,\n          12,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 0,\n        \"max\": 846,\n        \"num_unique_values\": 186,\n        \"samples\": [\n          52,\n          41,\n          183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mass\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.8841603203754405,\n        \"min\": 0.0,\n        \"max\": 67.1,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          19.9,\n          31.0,\n          38.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pedi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33132859501277484,\n        \"min\": 0.078,\n        \"max\": 2.42,\n        \"num_unique_values\": 517,\n        \"samples\": [\n          1.731,\n          0.426,\n          0.138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 21,\n        \"max\": 81,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          60,\n          47,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"tested_negative\",\n          \"tested_positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "features = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age','class']\n",
        "data=pd.read_csv( 'pima.csv',names=features)\n",
        "data.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G7J1wKcROUF1"
      },
      "outputs": [],
      "source": [
        "array = data.values\n",
        "\n",
        "# separate array into input and output components\n",
        "X = array[:,0:8] # 0 to 7 columns in X\n",
        "Y = array[:,8] #8th column in Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zZpC6UYuOUF1",
        "outputId": "33bd7277-fab1-4cb0-d153-0383e9a1c2df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " ...\n",
            " [1. 1. 1. ... 1. 0. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]]\n"
          ]
        }
      ],
      "source": [
        "binary=Binarizer(threshold=0.25).fit(X)\n",
        "binaryX=binary.transform(X)\n",
        "print(binaryX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkFmMeirOUF2"
      },
      "source": [
        "# Normalize or Standardize?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzQY-sXNOUF2"
      },
      "source": [
        "***Normalization*** is good to use when you know that the distribution of your ***data does not follow a Gaussian distribution.*** This can be useful in algorithms that do not assume any distribution of the data like K-Nearest Neighbors and Neural Networks.\n",
        "\n",
        "***Standardization,*** on the other hand, can be helpful in cases where the ***data follows a Gaussian distribution.*** However, this does not have to be necessarily true. Also, unlike normalization, standardization does not have a bounding range. So, even if you have outliers in your data, they will not be affected by standardization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2WFQJhPOUF2"
      },
      "source": [
        "# When Feature Scaling matters\n",
        "\n",
        "Some machine learning models are fundamentally based on distance matrix, also known as the distance-based classifier, for example, K-Nearest-Neighbours, SVM, and Neural Network. Feature scaling is extremely essential to those models, especially when the range of the features is very different. Otherwise, features with a large range will have a large influence in computing the distance.\n",
        "\n",
        "\n",
        "***Max-Min Normalisation*** typically allows us to transform the data with varying scales so that no specific dimension will dominate the statistics, and it does not require making a very strong assumption about the distribution of the data, such as k-nearest neighbours and artificial neural networks. ***However, Normalisation does not treat outliers very well.*** On the contrary, ***standardisation allows users to better handle the outliers and facilitate convergence for some computational algorithms like gradient descent.*** Therefore, we usually prefer standardisation over Min-Max Normalisation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjTVvnsfOUF2"
      },
      "source": [
        "# Scaling\n",
        "Most probably our dataset comprises of the attributes with varying scale, but we cannot provide such data to ML algorithm hence it requires rescaling. Data rescaling makes sure that attributes are at same scale. Generally, attributes are rescaled into the range of 0 and 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrYge857OUF2"
      },
      "source": [
        "### 1)Decimal Scaling\n",
        "\n",
        "### 2) Simple Feature Scaling\n",
        "\n",
        "### 3)Min-Max Normalization\n",
        "\n",
        "### 4)z-Score Normalization(zero-mean Normalization)\n",
        "\n",
        "Decimal Scaling Method For Normalization –\n",
        "It normalizes by moving the decimal point of values of the data. To normalize the data by this technique, we divide each value of the data by the maximum absolute value of data. The data value, vi, of data is normalized to vi‘ by using the formula below –\n",
        "\n",
        "### Decimal Scaling Method For Normalization –\n",
        "\n",
        "It normalizes by moving the decimal point of values of the data. To normalize the data by this technique, we divide each value of the data by the maximum absolute value of data. The data value, vi, of data is normalized to vi‘ by using the formula below –\n",
        "\n",
        "### V(new_i)=v(i)/10^i\n",
        "***\n",
        "***Let the input data is: -10, 201, 301, -401, 501, 601, 701***\n",
        "\n",
        "To normalize the above data,\n",
        "\n",
        "Step 1: Maximum absolute value in given data(m): 701\n",
        "\n",
        "Step 2: Divide the given data by 1000 (i.e j=3)\n",
        "\n",
        "Result: The normalized data is: -0.01, 0.201, 0.301, -0.401, 0.501, 0.601, 0.701\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "a6zXjtkROUF2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b700638e-7ad0-4c13-88f9-ebb68ab38747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "900 3\n",
            "[0.018, 0.012, 0.089, 0.121, 0.9, 0.045]\n"
          ]
        }
      ],
      "source": [
        "#Decimal Scaling Method For Normalization\n",
        "def Dec_scale(df):\n",
        "    p = max(df)\n",
        "    q = len(str(abs(p)))\n",
        "    print(p,q)\n",
        "    l=[]\n",
        "    for x in df:\n",
        "        l.append(x/10**q)\n",
        "    print(l)\n",
        "data=[18,12,89,121,900,45]\n",
        "Dec_scale(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "81TLp80fOUF3",
        "outputId": "a79a4dd8-31f1-4ff3-b558-47679fe2b399",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal.length  sepal.width  petal.length  petal.width        class\n",
            "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
            "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
            "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
            "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
            "4           5.0          3.6           1.4          0.2  Iris-setosa \n",
            "\n",
            "max sepal length value :  7.9 \n",
            "\n",
            "   sepal.length  sepal.width  petal.length  petal.width        class\n",
            "0      0.645570          3.5           1.4          0.2  Iris-setosa\n",
            "1      0.620253          3.0           1.4          0.2  Iris-setosa\n",
            "2      0.594937          3.2           1.3          0.2  Iris-setosa\n",
            "3      0.582278          3.1           1.5          0.2  Iris-setosa\n",
            "4      0.632911          3.6           1.4          0.2  Iris-setosa\n"
          ]
        }
      ],
      "source": [
        "#Simple Feature Scaling\n",
        "\n",
        "# Original Source : https://datahub.io/machine-learning/iris/r/iris.csv\n",
        "data=pd.read_csv('iris.csv')\n",
        "print(data.head(),'\\n')\n",
        "print(\"max sepal length value : \",data['sepal.length'].max(),'\\n')\n",
        "data['sepal.length']=data['sepal.length']/data['sepal.length'].max()\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sPaYmdc7OUF3",
        "outputId": "04326148-106a-4104-f1f8-d7857b7fa23a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.64556962 0.79545455 0.20289855 0.08      ]\n",
            " [0.62025316 0.68181818 0.20289855 0.08      ]\n",
            " [0.59493671 0.72727273 0.1884058  0.08      ]\n",
            " [0.58227848 0.70454545 0.2173913  0.08      ]\n",
            " [0.63291139 0.81818182 0.20289855 0.08      ]\n",
            " [0.6835443  0.88636364 0.24637681 0.16      ]\n",
            " [0.58227848 0.77272727 0.20289855 0.12      ]\n",
            " [0.63291139 0.77272727 0.2173913  0.08      ]\n",
            " [0.55696203 0.65909091 0.20289855 0.08      ]\n",
            " [0.62025316 0.70454545 0.2173913  0.04      ]\n",
            " [0.6835443  0.84090909 0.2173913  0.08      ]\n",
            " [0.60759494 0.77272727 0.23188406 0.08      ]\n",
            " [0.60759494 0.68181818 0.20289855 0.04      ]\n",
            " [0.5443038  0.68181818 0.15942029 0.04      ]\n",
            " [0.73417722 0.90909091 0.17391304 0.08      ]\n",
            " [0.72151899 1.         0.2173913  0.16      ]\n",
            " [0.64556962 0.79545455 0.20289855 0.12      ]\n",
            " [0.6835443  0.88636364 0.1884058  0.16      ]\n",
            " [0.72151899 0.86363636 0.24637681 0.12      ]\n",
            " [0.64556962 0.86363636 0.2173913  0.12      ]\n",
            " [0.6835443  0.77272727 0.24637681 0.08      ]\n",
            " [0.64556962 0.84090909 0.2173913  0.16      ]\n",
            " [0.58227848 0.81818182 0.14492754 0.08      ]\n",
            " [0.64556962 0.75       0.24637681 0.2       ]\n",
            " [0.60759494 0.77272727 0.27536232 0.08      ]\n",
            " [0.63291139 0.68181818 0.23188406 0.08      ]\n",
            " [0.63291139 0.77272727 0.23188406 0.16      ]\n",
            " [0.65822785 0.79545455 0.2173913  0.08      ]\n",
            " [0.65822785 0.77272727 0.20289855 0.08      ]\n",
            " [0.59493671 0.72727273 0.23188406 0.08      ]\n",
            " [0.60759494 0.70454545 0.23188406 0.08      ]\n",
            " [0.6835443  0.77272727 0.2173913  0.16      ]\n",
            " [0.65822785 0.93181818 0.2173913  0.04      ]\n",
            " [0.69620253 0.95454545 0.20289855 0.08      ]\n",
            " [0.62025316 0.70454545 0.2173913  0.04      ]\n",
            " [0.63291139 0.72727273 0.17391304 0.08      ]\n",
            " [0.69620253 0.79545455 0.1884058  0.08      ]\n",
            " [0.62025316 0.70454545 0.2173913  0.04      ]\n",
            " [0.55696203 0.68181818 0.1884058  0.08      ]\n",
            " [0.64556962 0.77272727 0.2173913  0.08      ]\n",
            " [0.63291139 0.79545455 0.1884058  0.12      ]\n",
            " [0.56962025 0.52272727 0.1884058  0.12      ]\n",
            " [0.55696203 0.72727273 0.1884058  0.08      ]\n",
            " [0.63291139 0.79545455 0.23188406 0.24      ]\n",
            " [0.64556962 0.86363636 0.27536232 0.16      ]\n",
            " [0.60759494 0.68181818 0.20289855 0.12      ]\n",
            " [0.64556962 0.86363636 0.23188406 0.08      ]\n",
            " [0.58227848 0.72727273 0.20289855 0.08      ]\n",
            " [0.67088608 0.84090909 0.2173913  0.08      ]\n",
            " [0.63291139 0.75       0.20289855 0.08      ]\n",
            " [0.88607595 0.72727273 0.68115942 0.56      ]\n",
            " [0.81012658 0.72727273 0.65217391 0.6       ]\n",
            " [0.87341772 0.70454545 0.71014493 0.6       ]\n",
            " [0.69620253 0.52272727 0.57971014 0.52      ]\n",
            " [0.82278481 0.63636364 0.66666667 0.6       ]\n",
            " [0.72151899 0.63636364 0.65217391 0.52      ]\n",
            " [0.79746835 0.75       0.68115942 0.64      ]\n",
            " [0.62025316 0.54545455 0.47826087 0.4       ]\n",
            " [0.83544304 0.65909091 0.66666667 0.52      ]\n",
            " [0.65822785 0.61363636 0.56521739 0.56      ]\n",
            " [0.63291139 0.45454545 0.50724638 0.4       ]\n",
            " [0.74683544 0.68181818 0.60869565 0.6       ]\n",
            " [0.75949367 0.5        0.57971014 0.4       ]\n",
            " [0.7721519  0.65909091 0.68115942 0.56      ]\n",
            " [0.70886076 0.65909091 0.52173913 0.52      ]\n",
            " [0.84810127 0.70454545 0.63768116 0.56      ]\n",
            " [0.70886076 0.68181818 0.65217391 0.6       ]\n",
            " [0.73417722 0.61363636 0.5942029  0.4       ]\n",
            " [0.78481013 0.5        0.65217391 0.6       ]\n",
            " [0.70886076 0.56818182 0.56521739 0.44      ]\n",
            " [0.74683544 0.72727273 0.69565217 0.72      ]\n",
            " [0.7721519  0.63636364 0.57971014 0.52      ]\n",
            " [0.79746835 0.56818182 0.71014493 0.6       ]\n",
            " [0.7721519  0.63636364 0.68115942 0.48      ]\n",
            " [0.81012658 0.65909091 0.62318841 0.52      ]\n",
            " [0.83544304 0.68181818 0.63768116 0.56      ]\n",
            " [0.86075949 0.63636364 0.69565217 0.56      ]\n",
            " [0.84810127 0.68181818 0.72463768 0.68      ]\n",
            " [0.75949367 0.65909091 0.65217391 0.6       ]\n",
            " [0.72151899 0.59090909 0.50724638 0.4       ]\n",
            " [0.69620253 0.54545455 0.55072464 0.44      ]\n",
            " [0.69620253 0.54545455 0.53623188 0.4       ]\n",
            " [0.73417722 0.61363636 0.56521739 0.48      ]\n",
            " [0.75949367 0.61363636 0.73913043 0.64      ]\n",
            " [0.6835443  0.68181818 0.65217391 0.6       ]\n",
            " [0.75949367 0.77272727 0.65217391 0.64      ]\n",
            " [0.84810127 0.70454545 0.68115942 0.6       ]\n",
            " [0.79746835 0.52272727 0.63768116 0.52      ]\n",
            " [0.70886076 0.68181818 0.5942029  0.52      ]\n",
            " [0.69620253 0.56818182 0.57971014 0.52      ]\n",
            " [0.69620253 0.59090909 0.63768116 0.48      ]\n",
            " [0.7721519  0.68181818 0.66666667 0.56      ]\n",
            " [0.73417722 0.59090909 0.57971014 0.48      ]\n",
            " [0.63291139 0.52272727 0.47826087 0.4       ]\n",
            " [0.70886076 0.61363636 0.60869565 0.52      ]\n",
            " [0.72151899 0.68181818 0.60869565 0.48      ]\n",
            " [0.72151899 0.65909091 0.60869565 0.52      ]\n",
            " [0.78481013 0.65909091 0.62318841 0.52      ]\n",
            " [0.64556962 0.56818182 0.43478261 0.44      ]\n",
            " [0.72151899 0.63636364 0.5942029  0.52      ]\n",
            " [0.79746835 0.75       0.86956522 1.        ]\n",
            " [0.73417722 0.61363636 0.73913043 0.76      ]\n",
            " [0.89873418 0.68181818 0.85507246 0.84      ]\n",
            " [0.79746835 0.65909091 0.8115942  0.72      ]\n",
            " [0.82278481 0.68181818 0.84057971 0.88      ]\n",
            " [0.96202532 0.68181818 0.95652174 0.84      ]\n",
            " [0.62025316 0.56818182 0.65217391 0.68      ]\n",
            " [0.92405063 0.65909091 0.91304348 0.72      ]\n",
            " [0.84810127 0.56818182 0.84057971 0.72      ]\n",
            " [0.91139241 0.81818182 0.88405797 1.        ]\n",
            " [0.82278481 0.72727273 0.73913043 0.8       ]\n",
            " [0.81012658 0.61363636 0.76811594 0.76      ]\n",
            " [0.86075949 0.68181818 0.79710145 0.84      ]\n",
            " [0.72151899 0.56818182 0.72463768 0.8       ]\n",
            " [0.73417722 0.63636364 0.73913043 0.96      ]\n",
            " [0.81012658 0.72727273 0.76811594 0.92      ]\n",
            " [0.82278481 0.68181818 0.79710145 0.72      ]\n",
            " [0.97468354 0.86363636 0.97101449 0.88      ]\n",
            " [0.97468354 0.59090909 1.         0.92      ]\n",
            " [0.75949367 0.5        0.72463768 0.6       ]\n",
            " [0.87341772 0.72727273 0.82608696 0.92      ]\n",
            " [0.70886076 0.63636364 0.71014493 0.8       ]\n",
            " [0.97468354 0.63636364 0.97101449 0.8       ]\n",
            " [0.79746835 0.61363636 0.71014493 0.72      ]\n",
            " [0.84810127 0.75       0.82608696 0.84      ]\n",
            " [0.91139241 0.72727273 0.86956522 0.72      ]\n",
            " [0.78481013 0.63636364 0.69565217 0.72      ]\n",
            " [0.7721519  0.68181818 0.71014493 0.72      ]\n",
            " [0.81012658 0.63636364 0.8115942  0.84      ]\n",
            " [0.91139241 0.68181818 0.84057971 0.64      ]\n",
            " [0.93670886 0.63636364 0.88405797 0.76      ]\n",
            " [1.         0.86363636 0.92753623 0.8       ]\n",
            " [0.81012658 0.63636364 0.8115942  0.88      ]\n",
            " [0.79746835 0.63636364 0.73913043 0.6       ]\n",
            " [0.7721519  0.59090909 0.8115942  0.56      ]\n",
            " [0.97468354 0.68181818 0.88405797 0.92      ]\n",
            " [0.79746835 0.77272727 0.8115942  0.96      ]\n",
            " [0.81012658 0.70454545 0.79710145 0.72      ]\n",
            " [0.75949367 0.68181818 0.69565217 0.72      ]\n",
            " [0.87341772 0.70454545 0.7826087  0.84      ]\n",
            " [0.84810127 0.70454545 0.8115942  0.96      ]\n",
            " [0.87341772 0.70454545 0.73913043 0.92      ]\n",
            " [0.73417722 0.61363636 0.73913043 0.76      ]\n",
            " [0.86075949 0.72727273 0.85507246 0.92      ]\n",
            " [0.84810127 0.75       0.82608696 1.        ]\n",
            " [0.84810127 0.68181818 0.75362319 0.92      ]\n",
            " [0.79746835 0.56818182 0.72463768 0.76      ]\n",
            " [0.82278481 0.68181818 0.75362319 0.8       ]\n",
            " [0.78481013 0.77272727 0.7826087  0.92      ]\n",
            " [0.74683544 0.68181818 0.73913043 0.72      ]]\n"
          ]
        }
      ],
      "source": [
        "#Simple Feature Scaling\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "dataWithNumericFeatures = data.loc[:, data.columns != \"class\"]\n",
        "simpleScale=MaxAbsScaler()\n",
        "rescaled=simpleScale.fit_transform(dataWithNumericFeatures)\n",
        "print(rescaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skOAFHw9OUF3"
      },
      "source": [
        "### Min-Max Normalization\n",
        "\n",
        "Min-max normalization is one of the most common ways to normalize data.\n",
        "\n",
        "**MinMaxScaler scales all the data features in the range [0, 1] or else in the range [-1, 1] if there are negative values in the dataset.** This scaling compresses all the inliers in the narrow range [0, 0.005].\n",
        "\n",
        "\n",
        "For every feature, the minimum value of that feature gets transformed into a 0,\n",
        "the maximum value gets transformed into a 1,\n",
        "\n",
        "and every other value gets transformed into a decimal between 0 and 1.\n",
        "\n",
        "##### F=Value-Min/Max-Min  \n",
        "\n",
        "Min-max normalization has one fairly significant downside: **it does not handle outliers very well.**\n",
        "\n",
        "Let (X1, X2) be a min and max boundary of an attribute and (Y1, Y2) be the new scale at which we are normalizing then for Vi  value of the attribute, the normalized value Ui is given as\n",
        "\n",
        "##### Example: Vi=300,000; X1= 125,000; X2= 925,000; Y1= 0; Y2= 1\n",
        "\n",
        "##### [(Vi-X1)/(X2-X1)]* (Y2-Y1)+Y1  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uETsY_LDOUF3",
        "outputId": "dc5d13a0-4d5f-46d0-e49b-6d214d3d9dc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     sepal.length  sepal.width  petal.length  petal.width           class\n",
            "0        0.645570     2.666667           1.4          0.2     Iris-setosa\n",
            "1        0.620253     2.166667           1.4          0.2     Iris-setosa\n",
            "2        0.594937     2.366667           1.3          0.2     Iris-setosa\n",
            "3        0.582278     2.266667           1.5          0.2     Iris-setosa\n",
            "4        0.632911     2.766667           1.4          0.2     Iris-setosa\n",
            "..            ...          ...           ...          ...             ...\n",
            "145      0.848101     2.166667           5.2          2.3  Iris-virginica\n",
            "146      0.797468     1.666667           5.0          1.9  Iris-virginica\n",
            "147      0.822785     2.166667           5.2          2.0  Iris-virginica\n",
            "148      0.784810     2.566667           5.4          2.3  Iris-virginica\n",
            "149      0.746835     2.166667           5.1          1.8  Iris-virginica\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "data['sepal.width']=data['sepal.width']-data['sepal.width'].min()/(data['sepal.width'].max()-data['sepal.width'].min())\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6Xjry24AOUF3",
        "outputId": "e5b0aa69-0f13-43ad-fce8-5dd53de244f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After MinMax Scaling\n",
            "MinMaxScaler() \n",
            "\n",
            "[ 1. 18.] \n",
            "\n",
            "[[0.   0.  ]\n",
            " [0.25 0.25]\n",
            " [0.5  0.5 ]\n",
            " [1.   1.  ]] \n",
            "\n",
            "[[1.5 0. ]]\n",
            "\n",
            " with -1 to 1 range \n",
            "\n",
            "[[-1.  -1. ]\n",
            " [-0.5 -0.5]\n",
            " [ 0.   0. ]\n",
            " [ 1.   1. ]]\n"
          ]
        }
      ],
      "source": [
        "#min-max Scaling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
        "\n",
        "print(\"After MinMax Scaling\")\n",
        "scaler = MinMaxScaler()\n",
        "print(scaler.fit(data),'\\n')\n",
        "print(scaler.data_max_,'\\n')\n",
        "print(scaler.transform(data),'\\n')\n",
        "print(scaler.transform([[2, 2]]))\n",
        "\n",
        "#changing to -1 to 1\n",
        "scaler1=MinMaxScaler(feature_range=(-1,1))\n",
        "rescaled=scaler1.fit_transform(data)\n",
        "print(\"\\n with -1 to 1 range \\n\")\n",
        "print(rescaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IK9g35HfOUF3",
        "outputId": "3b907470-06cc-4716-be54-05dd29e3a48c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   preg  plas  pres  skin  test  mass   pedi  age            class\n",
            "0     6   148    72    35     0  33.6  0.627   50  tested_positive\n",
            "1     1    85    66    29     0  26.6  0.351   31  tested_negative\n",
            "2     8   183    64     0     0  23.3  0.672   32  tested_positive\n",
            "3     1    89    66    23    94  28.1  0.167   21  tested_negative\n",
            "4     0   137    40    35   168  43.1  2.288   33  tested_positive\n",
            "[[6 148 72 ... 33.6 0.627 50]\n",
            " [1 85 66 ... 26.6 0.351 31]\n",
            " [8 183 64 ... 23.3 0.672 32]\n",
            " ...\n",
            " [5 121 72 ... 26.2 0.245 30]\n",
            " [1 126 60 ... 30.1 0.349 47]\n",
            " [1 93 70 ... 30.4 0.315 23]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "features = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age','class']\n",
        "data=pd.read_csv('pima.csv',names=features)\n",
        "print(data.head())\n",
        "db=data.values\n",
        "\n",
        "# separate array into input and output components\n",
        "X = db[:,0:8]\n",
        "Y = db[:,8]\n",
        "\n",
        "print(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "rescaledX = scaler.fit_transform(X)\n",
        "#rescaledY = scaler.fit_transform(Y)\n",
        "print(rescaledX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVlg45oFhaCS",
        "outputId": "b2878048-8ff5-4e52-9155-4a2e91950fff"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.29411765  0.48743719  0.18032787 ...  0.00149031 -0.53116994\n",
            "  -0.03333333]\n",
            " [-0.88235294 -0.14572864  0.08196721 ... -0.2071535  -0.76686593\n",
            "  -0.66666667]\n",
            " [-0.05882353  0.83919598  0.04918033 ... -0.30551416 -0.49274125\n",
            "  -0.63333333]\n",
            " ...\n",
            " [-0.41176471  0.2160804   0.18032787 ... -0.21907601 -0.85738685\n",
            "  -0.7       ]\n",
            " [-0.88235294  0.26633166 -0.01639344 ... -0.10283159 -0.76857387\n",
            "  -0.13333333]\n",
            " [-0.88235294 -0.06532663  0.14754098 ... -0.09388972 -0.79760888\n",
            "  -0.93333333]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hCB_zC4OOUF4",
        "outputId": "b88fb76e-1871-403b-efa2-5202e5ba40f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 85, 66, 29, 0, 26.6, 0.351, 31], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "X[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm4wS6MsOUF4"
      },
      "source": [
        "### Z-Score Normalization\n",
        "\n",
        "#Z-scores are linearly transformed data values having a mean of zero and a standard deviation of 1.\n",
        "\n",
        "#if we run a scatterplot of scores versus z-scores, all dots will be exactly on a straight\n",
        "\n",
        "#Z-scores are also known as standardized scores; they are scores (or data values) that have been given a common standard.\n",
        "\n",
        "####      Z-Score helps in the normalization of data!\n",
        "***A positive z-score says the data point is above average.\n",
        "A negative z-score says the data point is below average. ***\n",
        "\n",
        "####      Z-score= data_point-mean/S.D\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-9p0XzcOUF4"
      },
      "source": [
        "# standarization (or Z-score normalization)\n",
        "\n",
        "#### What is Standardization?\n",
        "\n",
        "**Standardization is scaling technique where the values are centered around the mean with a unit standard deviation. This means that the mean of the attribute becomes zero and the resultant distribution has a unit standard deviation.**\n",
        "\n",
        "The result of standardization (or Z-score normalization) is that the features will be rescaled to ensure the mean and the standard deviation to be 0 and 1, respectively\n",
        "\n",
        "This technique is to re-scale features value with the distribution value between 0 and 1 is useful for the optimization algorithms, such as gradient descent, that are used within machine learning algorithms that weight inputs (e.g., regression and neural networks). Rescaling is also used for algorithms that use distance measurements, for example, K-Nearest-Neighbours (KNN)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rp3tzWSOUF4"
      },
      "source": [
        "Standardization results in the rescaling of features, which in turn represents the properties of a standard normal distribution:\n",
        "\n",
        "mean = 0\n",
        "sd = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[:,4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3IlKJ2rhHx9",
        "outputId": "e79a78bc-52b8-4335-9eca-b725f1900511"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 94, 168, 0, 88, 0, 543, 0, 0, 0, 0, 846, 175, 0, 0, 230,\n",
              "       83, 96, 235, 0, 0, 0, 146, 115, 0, 140, 110, 0, 0, 245, 54, 0, 0,\n",
              "       192, 0, 0, 0, 207, 70, 0, 0, 240, 0, 0, 0, 0, 0, 0, 82, 36, 23,\n",
              "       300, 342, 0, 304, 110, 0, 142, 0, 0, 0, 128, 0, 0, 0, 0, 38, 100,\n",
              "       90, 140, 0, 270, 0, 0, 0, 0, 0, 0, 0, 0, 71, 0, 0, 125, 0, 71, 110,\n",
              "       0, 0, 176, 48, 0, 64, 228, 0, 76, 64, 220, 0, 0, 0, 40, 0, 152, 0,\n",
              "       140, 18, 36, 135, 495, 37, 0, 175, 0, 0, 0, 0, 51, 100, 0, 100, 0,\n",
              "       0, 99, 135, 94, 145, 0, 168, 0, 225, 0, 49, 140, 50, 92, 0, 325, 0,\n",
              "       0, 63, 0, 284, 0, 0, 119, 0, 0, 204, 0, 155, 485, 0, 0, 94, 135,\n",
              "       53, 114, 0, 105, 285, 0, 0, 156, 0, 0, 0, 78, 0, 130, 0, 48, 55,\n",
              "       130, 0, 130, 0, 0, 0, 92, 23, 0, 0, 0, 495, 58, 114, 160, 0, 94, 0,\n",
              "       0, 0, 210, 0, 48, 99, 318, 0, 0, 0, 44, 190, 0, 280, 0, 87, 0, 0,\n",
              "       0, 0, 130, 175, 271, 129, 120, 0, 0, 478, 0, 0, 190, 56, 32, 0, 0,\n",
              "       744, 53, 0, 370, 37, 0, 45, 0, 192, 0, 0, 0, 0, 88, 0, 176, 194, 0,\n",
              "       0, 680, 402, 0, 0, 0, 55, 0, 258, 0, 0, 0, 375, 150, 130, 0, 0, 0,\n",
              "       0, 67, 0, 0, 0, 0, 0, 56, 0, 45, 0, 57, 0, 116, 0, 278, 0, 122,\n",
              "       155, 0, 0, 135, 545, 220, 49, 75, 40, 74, 182, 194, 0, 120, 360,\n",
              "       215, 184, 0, 0, 135, 42, 0, 0, 105, 132, 148, 180, 205, 0, 148, 96,\n",
              "       85, 0, 94, 64, 0, 140, 0, 231, 0, 0, 29, 0, 168, 156, 0, 120, 68,\n",
              "       0, 52, 0, 0, 58, 255, 0, 0, 171, 0, 105, 73, 0, 0, 0, 108, 83, 0,\n",
              "       74, 0, 0, 0, 0, 43, 0, 0, 167, 0, 54, 249, 325, 0, 0, 0, 293, 83,\n",
              "       0, 0, 66, 140, 465, 89, 66, 94, 158, 325, 84, 75, 0, 72, 82, 0,\n",
              "       182, 59, 110, 50, 0, 0, 285, 81, 196, 0, 415, 87, 0, 275, 115, 0,\n",
              "       0, 0, 0, 0, 88, 0, 0, 165, 0, 0, 0, 579, 0, 176, 310, 61, 167, 474,\n",
              "       0, 0, 0, 115, 170, 76, 78, 0, 210, 277, 0, 180, 145, 180, 0, 85,\n",
              "       60, 0, 0, 0, 0, 0, 0, 0, 0, 50, 120, 0, 0, 14, 70, 92, 64, 63, 95,\n",
              "       0, 210, 0, 105, 0, 0, 71, 237, 60, 56, 0, 49, 0, 0, 105, 36, 100,\n",
              "       0, 140, 0, 0, 0, 0, 0, 0, 191, 110, 75, 0, 328, 0, 49, 125, 0, 250,\n",
              "       480, 265, 0, 0, 66, 0, 0, 122, 0, 0, 0, 76, 145, 193, 71, 0, 0, 79,\n",
              "       0, 0, 90, 170, 76, 0, 0, 210, 0, 0, 86, 105, 165, 0, 0, 326, 66,\n",
              "       130, 0, 0, 0, 0, 82, 105, 188, 0, 106, 0, 65, 0, 56, 0, 0, 0, 210,\n",
              "       155, 215, 190, 0, 56, 76, 225, 207, 166, 67, 0, 0, 106, 0, 44, 115,\n",
              "       215, 0, 0, 0, 0, 0, 274, 77, 54, 0, 88, 18, 126, 126, 165, 0, 0,\n",
              "       44, 120, 330, 63, 130, 0, 0, 0, 0, 0, 0, 0, 600, 0, 0, 0, 156, 0,\n",
              "       0, 140, 0, 115, 230, 185, 0, 25, 0, 120, 0, 0, 0, 126, 0, 0, 293,\n",
              "       41, 272, 182, 158, 194, 321, 0, 144, 0, 0, 15, 0, 0, 160, 0, 0,\n",
              "       115, 0, 54, 0, 0, 0, 0, 0, 90, 0, 183, 0, 0, 0, 66, 91, 46, 105, 0,\n",
              "       0, 0, 152, 440, 144, 159, 130, 0, 100, 106, 77, 0, 135, 540, 90,\n",
              "       200, 0, 70, 0, 0, 231, 130, 0, 132, 0, 0, 190, 100, 168, 0, 49,\n",
              "       240, 0, 0, 0, 0, 0, 265, 45, 0, 105, 0, 0, 205, 0, 0, 180, 180, 0,\n",
              "       0, 95, 125, 0, 480, 125, 0, 155, 0, 200, 0, 0, 0, 100, 0, 0, 335,\n",
              "       0, 160, 387, 22, 0, 291, 0, 392, 185, 0, 178, 0, 0, 200, 127, 105,\n",
              "       0, 0, 180, 0, 0, 0, 79, 0, 120, 165, 0, 0, 120, 0, 160, 0, 150, 94,\n",
              "       116, 0, 140, 105, 0, 57, 200, 0, 0, 74, 0, 510, 0, 110, 0, 0, 0, 0,\n",
              "       16, 0, 0, 180, 0, 112, 0, 0], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fLd9OIkiOUF4",
        "outputId": "797c78e4-a04f-4ac8-b0c6-4e4501c50aec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " 93.30710942770453 167.30710942770455 -0.6928905722954664\n",
            " 87.30710942770453 -0.6928905722954664 542.3071094277045\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 845.3071094277045 174.30710942770455\n",
            " -0.6928905722954664 -0.6928905722954664 229.30710942770455\n",
            " 82.30710942770453 95.30710942770453 234.30710942770455\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " 145.30710942770455 114.30710942770453 -0.6928905722954664\n",
            " 139.30710942770455 109.30710942770453 -0.6928905722954664\n",
            " -0.6928905722954664 244.30710942770455 53.30710942770453\n",
            " -0.6928905722954664 -0.6928905722954664 191.30710942770455\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " 206.30710942770455 69.30710942770453 -0.6928905722954664\n",
            " -0.6928905722954664 239.30710942770455 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 81.30710942770453\n",
            " 35.30710942770453 22.307109427704532 299.3071094277045 341.3071094277045\n",
            " -0.6928905722954664 303.3071094277045 109.30710942770453\n",
            " -0.6928905722954664 141.30710942770455 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 127.30710942770453\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 37.30710942770453 99.30710942770453 89.30710942770453\n",
            " 139.30710942770455 -0.6928905722954664 269.3071094277045\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 70.30710942770453\n",
            " -0.6928905722954664 -0.6928905722954664 124.30710942770453\n",
            " -0.6928905722954664 70.30710942770453 109.30710942770453\n",
            " -0.6928905722954664 -0.6928905722954664 175.30710942770455\n",
            " 47.30710942770453 -0.6928905722954664 63.30710942770453\n",
            " 227.30710942770455 -0.6928905722954664 75.30710942770453\n",
            " 63.30710942770453 219.30710942770455 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 39.30710942770453\n",
            " -0.6928905722954664 151.30710942770455 -0.6928905722954664\n",
            " 139.30710942770455 17.307109427704532 35.30710942770453\n",
            " 134.30710942770455 494.3071094277045 36.30710942770453\n",
            " -0.6928905722954664 174.30710942770455 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " 50.30710942770453 99.30710942770453 -0.6928905722954664 99.30710942770453\n",
            " -0.6928905722954664 -0.6928905722954664 98.30710942770453\n",
            " 134.30710942770455 93.30710942770453 144.30710942770455\n",
            " -0.6928905722954664 167.30710942770455 -0.6928905722954664\n",
            " 224.30710942770455 -0.6928905722954664 48.30710942770453\n",
            " 139.30710942770455 49.30710942770453 91.30710942770453\n",
            " -0.6928905722954664 324.3071094277045 -0.6928905722954664\n",
            " -0.6928905722954664 62.30710942770453 -0.6928905722954664\n",
            " 283.3071094277045 -0.6928905722954664 -0.6928905722954664\n",
            " 118.30710942770453 -0.6928905722954664 -0.6928905722954664\n",
            " 203.30710942770455 -0.6928905722954664 154.30710942770455\n",
            " 484.3071094277045 -0.6928905722954664 -0.6928905722954664\n",
            " 93.30710942770453 134.30710942770455 52.30710942770453 113.30710942770453\n",
            " -0.6928905722954664 104.30710942770453 284.3071094277045\n",
            " -0.6928905722954664 -0.6928905722954664 155.30710942770455\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " 77.30710942770453 -0.6928905722954664 129.30710942770455\n",
            " -0.6928905722954664 47.30710942770453 54.30710942770453\n",
            " 129.30710942770455 -0.6928905722954664 129.30710942770455\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " 91.30710942770453 22.307109427704532 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 494.3071094277045\n",
            " 57.30710942770453 113.30710942770453 159.30710942770455\n",
            " -0.6928905722954664 93.30710942770453 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 209.30710942770455\n",
            " -0.6928905722954664 47.30710942770453 98.30710942770453 317.3071094277045\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " 43.30710942770453 189.30710942770455 -0.6928905722954664\n",
            " 279.3071094277045 -0.6928905722954664 86.30710942770453\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 129.30710942770455 174.30710942770455\n",
            " 270.3071094277045 128.30710942770455 119.30710942770453\n",
            " -0.6928905722954664 -0.6928905722954664 477.3071094277045\n",
            " -0.6928905722954664 -0.6928905722954664 189.30710942770455\n",
            " 55.30710942770453 31.307109427704532 -0.6928905722954664\n",
            " -0.6928905722954664 743.3071094277045 52.30710942770453\n",
            " -0.6928905722954664 369.3071094277045 36.30710942770453\n",
            " -0.6928905722954664 44.30710942770453 -0.6928905722954664\n",
            " 191.30710942770455 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 87.30710942770453\n",
            " -0.6928905722954664 175.30710942770455 193.30710942770455\n",
            " -0.6928905722954664 -0.6928905722954664 679.3071094277045\n",
            " 401.3071094277045 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 54.30710942770453 -0.6928905722954664\n",
            " 257.3071094277045 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 374.3071094277045 149.30710942770455\n",
            " 129.30710942770455 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 66.30710942770453\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 55.30710942770453\n",
            " -0.6928905722954664 44.30710942770453 -0.6928905722954664\n",
            " 56.30710942770453 -0.6928905722954664 115.30710942770453\n",
            " -0.6928905722954664 277.3071094277045 -0.6928905722954664\n",
            " 121.30710942770453 154.30710942770455 -0.6928905722954664\n",
            " -0.6928905722954664 134.30710942770455 544.3071094277045\n",
            " 219.30710942770455 48.30710942770453 74.30710942770453 39.30710942770453\n",
            " 73.30710942770453 181.30710942770455 193.30710942770455\n",
            " -0.6928905722954664 119.30710942770453 359.3071094277045\n",
            " 214.30710942770455 183.30710942770455 -0.6928905722954664\n",
            " -0.6928905722954664 134.30710942770455 41.30710942770453\n",
            " -0.6928905722954664 -0.6928905722954664 104.30710942770453\n",
            " 131.30710942770455 147.30710942770455 179.30710942770455\n",
            " 204.30710942770455 -0.6928905722954664 147.30710942770455\n",
            " 95.30710942770453 84.30710942770453 -0.6928905722954664 93.30710942770453\n",
            " 63.30710942770453 -0.6928905722954664 139.30710942770455\n",
            " -0.6928905722954664 230.30710942770455 -0.6928905722954664\n",
            " -0.6928905722954664 28.307109427704532 -0.6928905722954664\n",
            " 167.30710942770455 155.30710942770455 -0.6928905722954664\n",
            " 119.30710942770453 67.30710942770453 -0.6928905722954664\n",
            " 51.30710942770453 -0.6928905722954664 -0.6928905722954664\n",
            " 57.30710942770453 254.30710942770455 -0.6928905722954664\n",
            " -0.6928905722954664 170.30710942770455 -0.6928905722954664\n",
            " 104.30710942770453 72.30710942770453 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 107.30710942770453\n",
            " 82.30710942770453 -0.6928905722954664 73.30710942770453\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 42.30710942770453 -0.6928905722954664\n",
            " -0.6928905722954664 166.30710942770455 -0.6928905722954664\n",
            " 53.30710942770453 248.30710942770455 324.3071094277045\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " 292.3071094277045 82.30710942770453 -0.6928905722954664\n",
            " -0.6928905722954664 65.30710942770453 139.30710942770455\n",
            " 464.3071094277045 88.30710942770453 65.30710942770453 93.30710942770453\n",
            " 157.30710942770455 324.3071094277045 83.30710942770453 74.30710942770453\n",
            " -0.6928905722954664 71.30710942770453 81.30710942770453\n",
            " -0.6928905722954664 181.30710942770455 58.30710942770453\n",
            " 109.30710942770453 49.30710942770453 -0.6928905722954664\n",
            " -0.6928905722954664 284.3071094277045 80.30710942770453\n",
            " 195.30710942770455 -0.6928905722954664 414.3071094277045\n",
            " 86.30710942770453 -0.6928905722954664 274.3071094277045\n",
            " 114.30710942770453 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " 87.30710942770453 -0.6928905722954664 -0.6928905722954664\n",
            " 164.30710942770455 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 578.3071094277045 -0.6928905722954664\n",
            " 175.30710942770455 309.3071094277045 60.30710942770453 166.30710942770455\n",
            " 473.3071094277045 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 114.30710942770453 169.30710942770455\n",
            " 75.30710942770453 77.30710942770453 -0.6928905722954664\n",
            " 209.30710942770455 276.3071094277045 -0.6928905722954664\n",
            " 179.30710942770455 144.30710942770455 179.30710942770455\n",
            " -0.6928905722954664 84.30710942770453 59.30710942770453\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 49.30710942770453\n",
            " 119.30710942770453 -0.6928905722954664 -0.6928905722954664\n",
            " 13.307109427704534 69.30710942770453 91.30710942770453 63.30710942770453\n",
            " 62.30710942770453 94.30710942770453 -0.6928905722954664\n",
            " 209.30710942770455 -0.6928905722954664 104.30710942770453\n",
            " -0.6928905722954664 -0.6928905722954664 70.30710942770453\n",
            " 236.30710942770455 59.30710942770453 55.30710942770453\n",
            " -0.6928905722954664 48.30710942770453 -0.6928905722954664\n",
            " -0.6928905722954664 104.30710942770453 35.30710942770453\n",
            " 99.30710942770453 -0.6928905722954664 139.30710942770455\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " 190.30710942770455 109.30710942770453 74.30710942770453\n",
            " -0.6928905722954664 327.3071094277045 -0.6928905722954664\n",
            " 48.30710942770453 124.30710942770453 -0.6928905722954664\n",
            " 249.30710942770455 479.3071094277045 264.3071094277045\n",
            " -0.6928905722954664 -0.6928905722954664 65.30710942770453\n",
            " -0.6928905722954664 -0.6928905722954664 121.30710942770453\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " 75.30710942770453 144.30710942770455 192.30710942770455 70.30710942770453\n",
            " -0.6928905722954664 -0.6928905722954664 78.30710942770453\n",
            " -0.6928905722954664 -0.6928905722954664 89.30710942770453\n",
            " 169.30710942770455 75.30710942770453 -0.6928905722954664\n",
            " -0.6928905722954664 209.30710942770455 -0.6928905722954664\n",
            " -0.6928905722954664 85.30710942770453 104.30710942770453\n",
            " 164.30710942770455 -0.6928905722954664 -0.6928905722954664\n",
            " 325.3071094277045 65.30710942770453 129.30710942770455\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 81.30710942770453 104.30710942770453\n",
            " 187.30710942770455 -0.6928905722954664 105.30710942770453\n",
            " -0.6928905722954664 64.30710942770453 -0.6928905722954664\n",
            " 55.30710942770453 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 209.30710942770455 154.30710942770455\n",
            " 214.30710942770455 189.30710942770455 -0.6928905722954664\n",
            " 55.30710942770453 75.30710942770453 224.30710942770455 206.30710942770455\n",
            " 165.30710942770455 66.30710942770453 -0.6928905722954664\n",
            " -0.6928905722954664 105.30710942770453 -0.6928905722954664\n",
            " 43.30710942770453 114.30710942770453 214.30710942770455\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 273.3071094277045\n",
            " 76.30710942770453 53.30710942770453 -0.6928905722954664 87.30710942770453\n",
            " 17.307109427704532 125.30710942770453 125.30710942770453\n",
            " 164.30710942770455 -0.6928905722954664 -0.6928905722954664\n",
            " 43.30710942770453 119.30710942770453 329.3071094277045 62.30710942770453\n",
            " 129.30710942770455 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 599.3071094277045\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " 155.30710942770455 -0.6928905722954664 -0.6928905722954664\n",
            " 139.30710942770455 -0.6928905722954664 114.30710942770453\n",
            " 229.30710942770455 184.30710942770455 -0.6928905722954664\n",
            " 24.307109427704532 -0.6928905722954664 119.30710942770453\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " 125.30710942770453 -0.6928905722954664 -0.6928905722954664\n",
            " 292.3071094277045 40.30710942770453 271.3071094277045 181.30710942770455\n",
            " 157.30710942770455 193.30710942770455 320.3071094277045\n",
            " -0.6928905722954664 143.30710942770455 -0.6928905722954664\n",
            " -0.6928905722954664 14.307109427704534 -0.6928905722954664\n",
            " -0.6928905722954664 159.30710942770455 -0.6928905722954664\n",
            " -0.6928905722954664 114.30710942770453 -0.6928905722954664\n",
            " 53.30710942770453 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " 89.30710942770453 -0.6928905722954664 182.30710942770455\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " 65.30710942770453 90.30710942770453 45.30710942770453 104.30710942770453\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " 151.30710942770455 439.3071094277045 143.30710942770455\n",
            " 158.30710942770455 129.30710942770455 -0.6928905722954664\n",
            " 99.30710942770453 105.30710942770453 76.30710942770453\n",
            " -0.6928905722954664 134.30710942770455 539.3071094277045\n",
            " 89.30710942770453 199.30710942770455 -0.6928905722954664\n",
            " 69.30710942770453 -0.6928905722954664 -0.6928905722954664\n",
            " 230.30710942770455 129.30710942770455 -0.6928905722954664\n",
            " 131.30710942770455 -0.6928905722954664 -0.6928905722954664\n",
            " 189.30710942770455 99.30710942770453 167.30710942770455\n",
            " -0.6928905722954664 48.30710942770453 239.30710942770455\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 264.3071094277045\n",
            " 44.30710942770453 -0.6928905722954664 104.30710942770453\n",
            " -0.6928905722954664 -0.6928905722954664 204.30710942770455\n",
            " -0.6928905722954664 -0.6928905722954664 179.30710942770455\n",
            " 179.30710942770455 -0.6928905722954664 -0.6928905722954664\n",
            " 94.30710942770453 124.30710942770453 -0.6928905722954664\n",
            " 479.3071094277045 124.30710942770453 -0.6928905722954664\n",
            " 154.30710942770455 -0.6928905722954664 199.30710942770455\n",
            " -0.6928905722954664 -0.6928905722954664 -0.6928905722954664\n",
            " 99.30710942770453 -0.6928905722954664 -0.6928905722954664\n",
            " 334.3071094277045 -0.6928905722954664 159.30710942770455\n",
            " 386.3071094277045 21.307109427704532 -0.6928905722954664\n",
            " 290.3071094277045 -0.6928905722954664 391.3071094277045\n",
            " 184.30710942770455 -0.6928905722954664 177.30710942770455\n",
            " -0.6928905722954664 -0.6928905722954664 199.30710942770455\n",
            " 126.30710942770453 104.30710942770453 -0.6928905722954664\n",
            " -0.6928905722954664 179.30710942770455 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 78.30710942770453\n",
            " -0.6928905722954664 119.30710942770453 164.30710942770455\n",
            " -0.6928905722954664 -0.6928905722954664 119.30710942770453\n",
            " -0.6928905722954664 159.30710942770455 -0.6928905722954664\n",
            " 149.30710942770455 93.30710942770453 115.30710942770453\n",
            " -0.6928905722954664 139.30710942770455 104.30710942770453\n",
            " -0.6928905722954664 56.30710942770453 199.30710942770455\n",
            " -0.6928905722954664 -0.6928905722954664 73.30710942770453\n",
            " -0.6928905722954664 509.3071094277045 -0.6928905722954664\n",
            " 109.30710942770453 -0.6928905722954664 -0.6928905722954664\n",
            " -0.6928905722954664 -0.6928905722954664 15.307109427704534\n",
            " -0.6928905722954664 -0.6928905722954664 179.30710942770455\n",
            " -0.6928905722954664 111.30710942770453 -0.6928905722954664\n",
            " -0.6928905722954664]\n",
            "[[5.23014681808529 147.2301468180853 71.23014681808529 ...\n",
            "  32.83014681808529 -0.14285318191470986 49.23014681808529]\n",
            " [0.23014681808529014 84.23014681808529 65.23014681808529 ...\n",
            "  25.830146818085293 -0.4188531819147099 30.23014681808529]\n",
            " [7.23014681808529 182.2301468180853 63.23014681808529 ...\n",
            "  22.530146818085292 -0.09785318191470982 31.23014681808529]\n",
            " ...\n",
            " [4.23014681808529 120.23014681808529 71.23014681808529 ...\n",
            "  25.43014681808529 -0.5248531819147099 29.23014681808529]\n",
            " [0.23014681808529014 125.23014681808529 59.23014681808529 ...\n",
            "  29.330146818085293 -0.4208531819147099 46.23014681808529]\n",
            " [0.23014681808529014 92.23014681808529 69.23014681808529 ...\n",
            "  29.63014681808529 -0.45485318191470986 22.23014681808529]]\n"
          ]
        }
      ],
      "source": [
        "#Z-Score\n",
        "\n",
        "X[:,4]=X[:,4]-X[:,4].mean()/X[:,4].std()\n",
        "print(X[:,4])\n",
        "\n",
        "X=X-X.mean()/X.std()\n",
        "print(X)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "3PyHzXA9OUF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c3518eb-b276-4788-ec8e-7b718285d8ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.  -1.5  3.  -6.4]\n",
            " [ 0.   3.  -1.3  4.1]\n",
            " [ 1.   2.3 -2.9 -4.3]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn import preprocessing\n",
        "input_data = np.array([[3, -1.5, 3, -6.4], [0, 3, -1.3, 4.1], [1, 2.3, -2.9, -4.3]])\n",
        "print(input_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "blLOUbc6OUF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "521557be-3d86-4d1d-cf67-3555e8e54572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean standardized data:  [ 1.33333333  1.26666667 -0.4        -2.2       ]\n",
            "Standard Deviation standardized data:  [1.24721913 1.97709102 2.49131826 4.53651849]\n"
          ]
        }
      ],
      "source": [
        "print(\"Mean standardized data: \",input_data.mean(axis=0)) #axis 0 is row\n",
        "print(\"Standard Deviation standardized data: \",input_data.std(axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***preprocessing.scale()***\n",
        "\n",
        "Standardize a dataset along any axis.\n",
        "\n",
        "Center to the mean and component wise scale to unit variance.\n",
        "The preprocessing.scale() function standardizes a dataset along any axis. This method centers the data on the mean and resizes the components in order to have a unit variance.\n",
        "\n",
        "The preprocessing.scale() algorithm puts your data on one scale\n",
        "X = [1, 4, 400, 10000, 100000]\n",
        "\n",
        "scale(x) is a simpler function for basic scaling without the transformer functionalities."
      ],
      "metadata": {
        "id": "_KrFsp08off3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vT064HhJOUF4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "775941a0-2554-464c-d8e1-a9582517a48e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.33630621 -1.39936232  1.36473933 -0.9258201 ]\n",
            " [-1.06904497  0.87670892 -0.36125453  1.38873015]\n",
            " [-0.26726124  0.5226534  -1.0034848  -0.46291005]]\n"
          ]
        }
      ],
      "source": [
        "standardData=preprocessing.scale(input_data) #default is axis=0\n",
        "print(standardData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KTJf7KHMOUF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "469e63c6-f826-4a14-c9ec-5c070369c128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean standardized data:  [ 5.55111512e-17 -3.70074342e-17  0.00000000e+00 -1.85037171e-17]\n",
            "Standard Deviation standardized data:  [1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "print(\"Mean standardized data: \",standardData.mean(axis=0))\n",
        "print(\"Standard Deviation standardized data: \",standardData.std(axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmMPN2lsOUF5"
      },
      "source": [
        "**Standardize Data - StandardScaler()**\n",
        "\n",
        "Standardization is a useful technique to transform attributes with a Gaussian distribution and differing means and standard deviations to a standard Gaussian distribution with a mean of 0 and a standard deviation of 1.\n",
        "\n",
        " We can standardize data using scikit-learn with the StandardScaler class.\n",
        "\n",
        "\n",
        " z = (x - u) / s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LkKnS1dPOUF5"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "cLgvc0FZOUF5",
        "outputId": "bf1ff53f-9de8-499f-afd1-169a4bab71c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.63994726  0.84832379  0.14964075  0.90726993 -0.69289057  0.20401277\n",
            "   0.46849198  1.4259954 ]\n",
            " [-0.84488505 -1.12339636 -0.16054575  0.53090156 -0.69289057 -0.68442195\n",
            "  -0.36506078 -0.19067191]\n",
            " [ 1.23388019  1.94372388 -0.26394125 -1.28821221 -0.69289057 -1.10325546\n",
            "   0.60439732 -0.10558415]\n",
            " [-0.84488505 -0.99820778 -0.16054575  0.15453319  0.12330164 -0.49404308\n",
            "  -0.92076261 -1.04154944]\n",
            " [-1.14185152  0.5040552  -1.50468724  0.90726993  0.76583594  1.4097456\n",
            "   5.4849091  -0.0204964 ]]\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler().fit(X)\n",
        "rescaledX = scaler.transform(X)\n",
        "\n",
        "# summarize transformed data\n",
        "print(rescaledX[0:5,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1b_77fxHOUGC",
        "outputId": "8beb1f6e-c757-473e-8d24-bcf17c526c0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.63994726  0.84832379  0.14964075  0.90726993 -0.69289057  0.20401277\n",
            "   0.46849198  1.4259954 ]\n",
            " [-0.84488505 -1.12339636 -0.16054575  0.53090156 -0.69289057 -0.68442195\n",
            "  -0.36506078 -0.19067191]\n",
            " [ 1.23388019  1.94372388 -0.26394125 -1.28821221 -0.69289057 -1.10325546\n",
            "   0.60439732 -0.10558415]\n",
            " [-0.84488505 -0.99820778 -0.16054575  0.15453319  0.12330164 -0.49404308\n",
            "  -0.92076261 -1.04154944]\n",
            " [-1.14185152  0.5040552  -1.50468724  0.90726993  0.76583594  1.4097456\n",
            "   5.4849091  -0.0204964 ]]\n"
          ]
        }
      ],
      "source": [
        "SS=StandardScaler()\n",
        "Sd=SS.fit_transform(X)\n",
        "print(Sd[0:5,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4CBNJMHOUGC"
      },
      "source": [
        "#### StandardScaler removes the mean and scales the data to unit variance.\n",
        "\n",
        "#### However, the outliers have an influence when computing the empirical mean and standard deviation which shrink the range of the feature values\n",
        "\n",
        "#### StandardScaler cannot guarantee balanced feature scales in the presence of outliers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kitWc3CiOUGD"
      },
      "source": [
        "# Encoding categorical data\n",
        "\n",
        "Sometimes our data is in qualitative form, that is we have texts as our data. We can find categories in text form. Now it gets complicated for machines to understand texts and process them, rather than numbers, since the models are based on mathematical equations and calculations. Therefore, we have to encode the categorical data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp5kbJK3OUGD"
      },
      "source": [
        "# Nominal and Ordinal Variables\n",
        "\n",
        "Nominal Variable (Categorical). Variable comprises a finite set of discrete values with no relationship between values.\n",
        "\n",
        "Ordinal Variable. Variable comprises a finite set of discrete values with a ranked ordering between values.\n",
        "\n",
        "Some algorithms can work with categorical data directly.\n",
        "\n",
        "For example, a decision tree can be learned directly from categorical data with no data transform required (this depends on the specific implementation).\n",
        "\n",
        "Many machine learning algorithms cannot operate on label data directly. They require all input variables and output variables to be numeric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGi2lqYWOUGE"
      },
      "source": [
        "# Encoding Categorical Data\n",
        "\n",
        "There are three common approaches for converting ordinal and categorical variables to numerical values. They are:\n",
        "\n",
        "### Ordinal Encoding(label encoding)\n",
        "\n",
        "### One-Hot Encoding\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De5PVw12OUGE"
      },
      "source": [
        "# Label Encoding (ordinal)\n",
        "\n",
        "\n",
        "In ordinal encoding, each unique category value is assigned an integer value.\n",
        "\n",
        "For example, “red” is 1, “green” is 2, and “blue” is 3.\n",
        "\n",
        "In label encoding, we map each category to a number or a label. The labels chosen for the categories have no relationship. So categories that have some ties or are close to each other lose such information after encoding.\n",
        "\n",
        "Limitation of label Encoding:\n",
        "\n",
        "-Label encoding convert the data in machine readable form, but it assigns a unique number(starting from 0) to each class of data.\n",
        "\n",
        "-This may lead to the generation of priority issue in training of data sets.\n",
        "\n",
        "\n",
        "-A label with high value may be considered to have high priority than a label having lower value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "tTUbwcHbOUGE",
        "outputId": "158ebe8c-e918-4d5e-ff46-bb5e82851b5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AB ==> 0\n",
            "CD ==> 1\n",
            "DX ==> 2\n",
            "MN ==> 3\n",
            "PK ==> 4\n",
            "[1, 3, 4, 0, 1, 0, 4, 2, 3]\n"
          ]
        }
      ],
      "source": [
        "#Label Encoding\n",
        "from sklearn import preprocessing\n",
        "encode=preprocessing.LabelEncoder()\n",
        "data=['AB','CD','PK','DX','MN']\n",
        "encode.fit(data)\n",
        "for i,item in enumerate(encode.classes_):\n",
        "    print(item,'==>',i)\n",
        "myinput=['CD','MN','PK','AB','CD','AB','PK','DX','MN']\n",
        "\n",
        "lbl=encode.transform(myinput)\n",
        "print(list(lbl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "2LmjYeK-OUGE",
        "outputId": "30eb37d2-93ab-4a4b-e2b0-3058f254ea88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-726ab1d4ee11>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "# Label Encoding example\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "df.head()\n",
        "df['class'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AufxfnlMOUGE"
      },
      "outputs": [],
      "source": [
        "#df['variety'].unique()\n",
        "\n",
        "# Import label encoder\n",
        "from sklearn import preprocessing\n",
        "# label_encoder object knows how to understand word labels.\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "# Encode labels in column 'species'.\n",
        "df['class']= label_encoder.fit_transform(df['class'])\n",
        "#f=df['variety'].unique()\n",
        "#print(f)\n",
        "for i,item in enumerate(label_encoder.classes_):\n",
        "    print(item,'==>',i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FmycuYHOUGE"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvgZ-gmXOUGE"
      },
      "source": [
        "# OneHotEncoding\n",
        "\n",
        "**Sometimes in datasets, we encounter columns that contain numbers of no specific order of preference. The data in the column usually denotes a category or value of the category and also when the data in the column is label encoded. This confuses the machine learning model, to avoid this the data in the column should be One Hot encoded.**\n",
        "\n",
        "It refers to splitting the column which contains numerical categorical data to many columns depending on the number of categories present in that column. Each column contains “0” or “1” corresponding to which column it has been placed.\n",
        "\n",
        "\n",
        "One hot encoding is the most widespread approach, and it works very well unless your categorical variable takes on a large number of values (i.e. you generally won't use it for variables taking more than 15 different values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eq6Obx-OUGF"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 1, 0],\n",
        "                   'C': [0, 2, 2], 'D': [0, 1, 1]})\n",
        "print(df)\n",
        "df_onehot = OneHotEncoder()\n",
        "data = df_onehot.fit_transform(df)\n",
        "#get_feature_names_out() : Get output feature names for transformation.\n",
        "df1 = pd.DataFrame(data.toarray(), columns=df_onehot.get_feature_names_out(), dtype=int)\n",
        "df1"
      ],
      "metadata": {
        "id": "icDzJFKuy12J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeJIFkcxOUGF"
      },
      "outputs": [],
      "source": [
        "iris=load_iris()\n",
        "iris.feature_names\n",
        "features=pd.DataFrame(iris.feature_names)\n",
        "iris.target_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF0LU021OUGF"
      },
      "outputs": [],
      "source": [
        "X=pd.DataFrame(iris.data)\n",
        "Y=pd.DataFrame(iris.target)\n",
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8yiduc9OUGF"
      },
      "outputs": [],
      "source": [
        "encoder = OneHotEncoder(sparse_output=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVWFXnweOUGF"
      },
      "outputs": [],
      "source": [
        "ohe=encoder.fit_transform(Y)\n",
        "print(ohe)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X, y = make_classification(random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
        "\n",
        "pipe.fit(X_train, y_train)  # apply scaling on training data\n",
        "\n",
        "pipe.score(X_test, y_test)  # apply scaling on testing data, without leaking training data.\n"
      ],
      "metadata": {
        "id": "exloo9Z82eqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "w9ll8mCz3BPE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
