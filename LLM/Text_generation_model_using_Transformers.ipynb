{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "L4X32nxxXMTE",
    "outputId": "21b87e23-8077-42d3-c529-ef88bcbe1753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 2.7755712151527403\n",
      "Epoch: 1 Loss: 1.9283055186271667\n",
      "Epoch: 2 Loss: 1.6731786102056503\n",
      "Epoch: 3 Loss: 1.4861217498779298\n",
      "Epoch: 4 Loss: 1.3361248433589936\n",
      "Epoch: 5 Loss: 1.185829444229603\n",
      "Epoch: 6 Loss: 1.050405140221119\n",
      "Epoch: 7 Loss: 0.9306383252143859\n",
      "Epoch: 8 Loss: 0.8201606050133705\n",
      "Epoch: 9 Loss: 0.7334136128425598\n",
      "Epoch: 10 Loss: 0.666859944909811\n",
      "Epoch: 11 Loss: 0.6081490024924279\n",
      "Epoch: 12 Loss: 0.5402705639600753\n",
      "Epoch: 13 Loss: 0.48038235008716584\n",
      "Epoch: 14 Loss: 0.4148778297007084\n",
      "Epoch: 15 Loss: 0.36019440218806265\n",
      "Epoch: 16 Loss: 0.3180326525121927\n",
      "Epoch: 17 Loss: 0.2714605838060379\n",
      "Epoch: 18 Loss: 0.2367452558130026\n",
      "Epoch: 19 Loss: 0.20312368124723434\n",
      "Epoch: 20 Loss: 0.17371167056262493\n",
      "Epoch: 21 Loss: 0.15486931204795837\n",
      "Epoch: 22 Loss: 0.13133458215743304\n",
      "Epoch: 23 Loss: 0.11646672934293748\n",
      "Epoch: 24 Loss: 0.10483342222869396\n",
      "Epoch: 25 Loss: 0.08881416013464331\n",
      "Epoch: 26 Loss: 0.08075262252241373\n",
      "Epoch: 27 Loss: 0.06983621753752231\n",
      "Epoch: 28 Loss: 0.0693563712760806\n",
      "Epoch: 29 Loss: 0.061997848376631734\n",
      "Epoch: 30 Loss: 0.05203701020218432\n",
      "Epoch: 31 Loss: 0.04734315574169159\n",
      "Epoch: 32 Loss: 0.04826427269726992\n",
      "Epoch: 33 Loss: 0.048511539958417414\n",
      "Epoch: 34 Loss: 0.0397349099162966\n",
      "Epoch: 35 Loss: 0.03711029319092631\n",
      "Epoch: 36 Loss: 0.034450010396540165\n",
      "Epoch: 37 Loss: 0.03885747333988547\n",
      "Epoch: 38 Loss: 0.03153204214759171\n",
      "Epoch: 39 Loss: 0.026681805215775966\n",
      "Epoch: 40 Loss: 0.035624270839616654\n",
      "Epoch: 41 Loss: 0.030514995101839304\n",
      "Epoch: 42 Loss: 0.02427225050050765\n",
      "Epoch: 43 Loss: 0.024444698449224235\n",
      "Epoch: 44 Loss: 0.025968539947643875\n",
      "Epoch: 45 Loss: 0.031946931197308\n",
      "Epoch: 46 Loss: 0.03704500740859658\n",
      "Epoch: 47 Loss: 0.025035285344347357\n",
      "Epoch: 48 Loss: 0.02208578446879983\n",
      "Epoch: 49 Loss: 0.02532473418395966\n",
      "Epoch: 50 Loss: 0.024069591285660864\n",
      "Epoch: 51 Loss: 0.026692435750737785\n",
      "Epoch: 52 Loss: 0.02510485069360584\n",
      "Epoch: 53 Loss: 0.023423057375475766\n",
      "Epoch: 54 Loss: 0.021492915076669304\n",
      "Epoch: 55 Loss: 0.016105624521151184\n",
      "Epoch: 56 Loss: 0.02339647364569828\n",
      "Epoch: 57 Loss: 0.024720229115337132\n",
      "Epoch: 58 Loss: 0.021933726174756883\n",
      "Epoch: 59 Loss: 0.020631818624679\n",
      "Epoch: 60 Loss: 0.01971082963864319\n",
      "Epoch: 61 Loss: 0.02232606625184417\n",
      "Epoch: 62 Loss: 0.01580287767574191\n",
      "Epoch: 63 Loss: 0.014245872513856738\n",
      "Epoch: 64 Loss: 0.012663454213179649\n",
      "Epoch: 65 Loss: 0.014000830170698465\n",
      "Epoch: 66 Loss: 0.014554867520928383\n",
      "Epoch: 67 Loss: 0.014914765837602317\n",
      "Epoch: 68 Loss: 0.012278483645059169\n",
      "Epoch: 69 Loss: 0.012192079063970596\n",
      "Epoch: 70 Loss: 0.009838681505061685\n",
      "Epoch: 71 Loss: 0.01076299960259348\n",
      "Epoch: 72 Loss: 0.012281069718301296\n",
      "Epoch: 73 Loss: 0.012925189221277833\n",
      "Epoch: 74 Loss: 0.01288070499431342\n",
      "Epoch: 75 Loss: 0.018569402187131344\n",
      "Epoch: 76 Loss: 0.010874794225674122\n",
      "Epoch: 77 Loss: 0.007637682286440395\n",
      "Epoch: 78 Loss: 0.009531403408618643\n",
      "Epoch: 79 Loss: 0.008096379510243423\n",
      "Epoch: 80 Loss: 0.008401450923702213\n",
      "Epoch: 81 Loss: 0.011383260984439402\n",
      "Epoch: 82 Loss: 0.008916886313818395\n",
      "Epoch: 83 Loss: 0.008001405233517288\n",
      "Epoch: 84 Loss: 0.012812277907505632\n",
      "Epoch: 85 Loss: 0.009732166235335172\n",
      "Epoch: 86 Loss: 0.007095295564795379\n",
      "Epoch: 87 Loss: 0.006665445698308759\n",
      "Epoch: 88 Loss: 0.006832689986913465\n",
      "Epoch: 89 Loss: 0.005969347077189014\n",
      "Epoch: 90 Loss: 0.004827545341686346\n",
      "Epoch: 91 Loss: 0.005093600464169868\n",
      "Epoch: 92 Loss: 0.003503489342983812\n",
      "Epoch: 93 Loss: 0.0047385810874402525\n",
      "Epoch: 94 Loss: 0.004636492949794046\n",
      "Epoch: 95 Loss: 0.004974794262670912\n",
      "Epoch: 96 Loss: 0.00400597614061553\n",
      "Epoch: 97 Loss: 0.004614171534194611\n",
      "Epoch: 98 Loss: 0.004111651415587403\n",
      "Epoch: 99 Loss: 0.003850908023014199\n",
      "Epoch: 100 Loss: 0.003591345687163994\n",
      "Epoch: 101 Loss: 0.006625715241534635\n",
      "Epoch: 102 Loss: 0.0033233102352824063\n",
      "Epoch: 103 Loss: 0.003622009932587389\n",
      "Epoch: 104 Loss: 0.004809784911049064\n",
      "Epoch: 105 Loss: 0.004048273217631504\n",
      "Epoch: 106 Loss: 0.004373679448326584\n",
      "Epoch: 107 Loss: 0.004469312146102311\n",
      "Epoch: 108 Loss: 0.004396545575582422\n",
      "Epoch: 109 Loss: 0.004852985462639481\n",
      "Epoch: 110 Loss: 0.004505601621349342\n",
      "Epoch: 111 Loss: 0.008992793786455877\n",
      "Epoch: 112 Loss: 0.01370916329906322\n",
      "Epoch: 113 Loss: 0.01292540990980342\n",
      "Epoch: 114 Loss: 0.005104294420743827\n",
      "Epoch: 115 Loss: 0.00487494942790363\n",
      "Epoch: 116 Loss: 0.0034560797459562307\n",
      "Epoch: 117 Loss: 0.002686692053976003\n",
      "Epoch: 118 Loss: 0.005316424743796233\n",
      "Epoch: 119 Loss: 0.00836260627838783\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint ./trained_model\n",
      "cats rule the world. dogs are the best. elephants have long truiruiruiruiruirus trus ruuurururururuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuu\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Define a new class 'TokenEmbedding' that inherits from torch.nn.Module, which is the base class for all PyTorch models/layers.\n",
    "class TokenEmbedding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch module that converts tokens into embeddings.\n",
    "\n",
    "    Input dimension is: (batch_size, sequence_length) Note: batch_size = Number of samples you're feeding into the model at once.\n",
    "                                                      sequence_length = Number of tokens (e.g. characters, words) in each sample.\n",
    "    Output dimension is: (batch_size, sequence_length, d_model)\n",
    "    \"\"\"\n",
    "    #d_model: Size of each embedding vector.\n",
    "    def __init__(self, d_model, number_of_tokens):\n",
    "        super().__init__()\n",
    "        #Initializes a learnable embedding layer, Internally, this creates a table of shape (number_of_tokens, d_model) that stores an embedding vector for each token ID.\n",
    "        self.embedding_layer = torch.nn.Embedding(\n",
    "            num_embeddings=number_of_tokens,\n",
    "            embedding_dim=d_model\n",
    "        )\n",
    "    #Defines the forward pass of the model.\n",
    "    #Input x: A tensor of token IDs of shape (batch_size, sequence_length).\n",
    "    #Output: Looks up and returns the corresponding embeddings, resulting in a tensor of shape (batch_size, sequence_length, d_model).\n",
    "    def forward(self, x):\n",
    "        return self.embedding_layer(x)\n",
    "\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch module that creates a positional encoding matrix. This matrix will later be added to the\n",
    "    transformer's input embeddings to provide a sense of position of the sequence elements.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, max_sequence_length):\n",
    "        super().__init__()\n",
    "        #Store constructor arguments for use later.\n",
    "        self.d_model = d_model\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.positional_encoding = self.create_positional_encoding()\n",
    "\n",
    "    def create_positional_encoding(self):\n",
    "        \"\"\"\n",
    "        Creates a positional encoding matrix of size (max_sequence_length, d_model).\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize positional encoding matrix, a NumPy array of shape (max_sequence_length, d_model) with all zeros.\n",
    "        positional_encoding = np.zeros((self.max_sequence_length, self.d_model))\n",
    "\n",
    "        # Calculate positional encoding for each position and each dimension,We use sin for even vector slots, cos for odd ones.\n",
    "        #This creates unique patterns for each word based on its position.It helps the model understand sequence and distance between words.\n",
    "        for pos in range(self.max_sequence_length):\n",
    "            for i in range(0, self.d_model, 2):\n",
    "                # Apply sin to even indices in the array; indices in Python start at 0 so i is even.\n",
    "                positional_encoding[pos, i] = np.sin(pos / (10000 ** ((2 * i) / self.d_model)))\n",
    "\n",
    "                if i + 1 < self.d_model:\n",
    "                    # Apply cos to odd indices in the array; we add 1 to i because indices in Python start at 0.\n",
    "                    positional_encoding[pos, i + 1] = np.cos(pos / (10000 ** ((2 * i) / self.d_model)))\n",
    "\n",
    "        # Convert numpy array to PyTorch tensor and return it\n",
    "        return torch.from_numpy(positional_encoding).float().to(get_device())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Adds the positional encoding to the input embeddings at the corresponding positions.x is the input embedding tensor with shape:\n",
    "        (batch_size, sequence_length, d_model)So:\n",
    "        x.size(0) → batch size\n",
    "        x.size(1) → sequence length (how many tokens are in the input)\n",
    "        x.size(2) → embedding dimension (d_model)\n",
    "        \"\"\"\n",
    "        # Add positional encodings to input embeddings. [:x.size(1)] selects rows from position 0 up to sequence_length - 1, [:] selects all columns, which are the d_model dimensions\n",
    "        return x + self.positional_encoding[:x.size(1), :]\n",
    "\n",
    "\n",
    "class MaskedSelfAttention(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch module for a self attention layer.\n",
    "    This layer is used in the MultiHeadedSelfAttention module.\n",
    "    embedding_dimension: dimension of the input embeddings (e.g., 512)\n",
    "    head_dimension: dimension for the query/key/value vectors in this attention head (usually smaller, e.g., 64)\n",
    "    Layers:\n",
    "    query_layer, key_layer, value_layer: Linear transformations that project the input embeddings into query, key, and value vectors.\n",
    "    softmax: To normalize attention weights so they sum to 1.\n",
    "\n",
    "    Input dimension is: (batch_size, sequence_length, embedding_dimension)\n",
    "    Output dimension is: (batch_size, sequence_length, head_dimension)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dimension, head_dimension):\n",
    "        super().__init__()\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.head_dimension = head_dimension\n",
    "        self.query_layer = torch.nn.Linear(embedding_dimension, self.head_dimension)\n",
    "        self.key_layer = torch.nn.Linear(embedding_dimension, self.head_dimension)\n",
    "        self.value_layer = torch.nn.Linear(embedding_dimension, self.head_dimension)\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Compute the self attention.\n",
    "\n",
    "        x dimension is: (batch_size, sequence_length, embedding_dimension)\n",
    "        output dimension is: (batch_size, sequence_length, head_dimension)\n",
    "        mask dimension is: (batch_size, sequence_length)\n",
    "\n",
    "        mask values are: 0 or 1. 0 means the token is masked, 1 means the token is not masked.\n",
    "        \"\"\"\n",
    "\n",
    "        # x dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
    "        # query, key, value dimensions are: (batch_size, sequence_length, head_dimension)\n",
    "        query = self.query_layer(x)\n",
    "        key = self.key_layer(x)\n",
    "        value = self.value_layer(x)\n",
    "\n",
    "        # Calculate the attention weights.\n",
    "        # attention_weights dimensions are: (batch_size, sequence_length, sequence_length)\n",
    "        attention_weights = torch.matmul(query, key.transpose(-2, -1))\n",
    "\n",
    "        # Scale the attention weights.\n",
    "        attention_weights = attention_weights / np.sqrt(self.head_dimension)\n",
    "\n",
    "        # Apply the mask to the attention weights, by setting the masked tokens to a very low value.\n",
    "        # This will make the softmax output 0 for these values.\n",
    "        mask = mask.reshape(attention_weights.shape[0], 1, attention_weights.shape[2])\n",
    "        attention_weights = attention_weights.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        # Softmax makes sure all scores are between 0 and 1 and the sum of scores is 1.\n",
    "        # attention_scores dimensions are: (batch_size, sequence_length, sequence_length)\n",
    "        attention_scores = self.softmax(attention_weights)\n",
    "\n",
    "        # Batch matrix multiplication, The attention scores are multiplied by the value\n",
    "        # Values of tokens with high attention score get highlighted because they are multiplied by a larger number,\n",
    "        # and tokens with low attention score get drowned out because they are multiplied by a smaller number.\n",
    "        # Output dimensions are: (batch_size, sequence_length, head_dimension)\n",
    "        return torch.bmm(attention_scores, value)\n",
    "\n",
    "\n",
    "class MaskedMultiHeadedSelfAttention(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch module for a multi head attention layer.\n",
    "    Each head gets the same input and applies different learned W_q, W_k, W_v\n",
    "    Each head computes its own attention scores and weighted values\n",
    "    Outputs from all heads are concatenated\n",
    "    Final linear layer combines them\n",
    "    Input dimension is: (batch_size, sequence_length, embedding_dimension)\n",
    "    Output dimension is: (batch_size, sequence_length, embedding_dimension)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dimension, number_of_heads):\n",
    "        super().__init__()\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.head_dimension = embedding_dimension // number_of_heads\n",
    "        self.number_of_heads = number_of_heads\n",
    "\n",
    "        # Create the self attention modules\n",
    "        self.self_attentions = torch.nn.ModuleList(\n",
    "            [MaskedSelfAttention(embedding_dimension, self.head_dimension) for _ in range(number_of_heads)])\n",
    "\n",
    "        # Create a linear layer to combine the outputs of the self attention modules\n",
    "        self.output_layer = torch.nn.Linear(number_of_heads * self.head_dimension, embedding_dimension)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Compute the multi head attention.\n",
    "\n",
    "        x dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
    "        mask dimensions are: (batch_size, sequence_length)\n",
    "        mask values are: 0 or 1. 0 means the token is masked, 1 means the token is not masked.\n",
    "        \"\"\"\n",
    "        # Compute the self attention for each head\n",
    "        # self_attention_outputs dimensions are:\n",
    "        # (number_of_heads, batch_size, sequence_length, head_dimension)\n",
    "        self_attention_outputs = [self_attention(x, mask) for self_attention in self.self_attentions]\n",
    "\n",
    "        # Concatenate the self attention outputs\n",
    "        # self_attention_outputs_concatenated dimensions are:\n",
    "        # (batch_size, sequence_length, number_of_heads * head_dimension)\n",
    "        concatenated_self_attention_outputs = torch.cat(self_attention_outputs, dim=2)\n",
    "\n",
    "        \n",
    "        # Apply the output layer to the concatenated self attention outputs\n",
    "        # output dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
    "        return self.output_layer(concatenated_self_attention_outputs)\n",
    "\n",
    "\n",
    "class FeedForward(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch module for a feed forward layer.\n",
    "\n",
    "    A feed forward layer is a fully connected layer with a ReLU activation function in between.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dimension, feed_forward_dimension):\n",
    "        super().__init__()\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.feed_forward_dimension = feed_forward_dimension\n",
    "        #Expands dimensionality (embed_dim → ff_dim)\n",
    "        self.linear_1 = torch.nn.Linear(embedding_dimension, feed_forward_dimension)\n",
    "        #Brings it back (ff_dim → embed_dim)\n",
    "        self.linear_2 = torch.nn.Linear(feed_forward_dimension, embedding_dimension)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Compute the feed forward layer.\n",
    "        \"\"\"\n",
    "        return self.linear_2(torch.relu(self.linear_1(x)))\n",
    "\n",
    "\n",
    "class DecoderLayer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch module for an encoder layer.\n",
    "\n",
    "    An encoder layer consists of a multi-headed self attention layer, a feed forward layer and dropout.\n",
    "\n",
    "    Input dimension is: (batch_size, sequence_length, embedding_dimension)\n",
    "    Output dimension is: (batch_size, sequence_length, embedding_dimension)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_dimension,\n",
    "            number_of_heads,\n",
    "            feed_forward_dimension,\n",
    "            dropout_rate\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.number_of_heads = number_of_heads\n",
    "        self.feed_forward_dimension = feed_forward_dimension\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.multi_headed_self_attention = MaskedMultiHeadedSelfAttention(embedding_dimension, number_of_heads)\n",
    "        self.feed_forward = FeedForward(embedding_dimension, feed_forward_dimension)\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        self.layer_normalization_1 = torch.nn.LayerNorm(embedding_dimension)\n",
    "        self.layer_normalization_2 = torch.nn.LayerNorm(embedding_dimension)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Compute the encoder layer.\n",
    "\n",
    "        x dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
    "        mask dimensions are: (batch_size, sequence_length)\n",
    "        mask values are: 0 or 1. 0 means the token is masked, 1 means the token is not masked.\n",
    "        \"\"\"\n",
    "\n",
    "        # Layer normalization 1,stabilize and speed up training by normalizing inputs across features (embedding dimensions).\n",
    "        normalized_x = self.layer_normalization_1(x)\n",
    "\n",
    "        # Multi headed self attention,Allows each token to attend to earlier tokens in the sequence (but not future tokens), \n",
    "        # preserving causality. That’s why it's masked.Multi-headed attention means the model learns different types of relationships or dependencies in parallel (each head focuses differently).\n",
    "        attention_output = self.multi_headed_self_attention(normalized_x, mask)\n",
    "\n",
    "        # Residual output, Instead of passing attention output alone, we add it back to the original input x.\n",
    "        residual_output = x + attention_output\n",
    "\n",
    "        # Layer normalization 2, Normalizes the data again before passing it to the feed-forward network.\n",
    "        normalized_residual_output = self.layer_normalization_2(residual_output)\n",
    "\n",
    "        # Feed forward,It adds non-linearity and depth, enabling the model to learn complex transformations independently for each token.\n",
    "        feed_forward_output = self.feed_forward(normalized_residual_output)\n",
    "\n",
    "        # Dropout,Prevents overfitting by randomly zeroing some values during training.\n",
    "        if self.training:\n",
    "            feed_forward_output = self.dropout(feed_forward_output)\n",
    "\n",
    "        # Residual output,nstead of using only the output of the feed-forward block, we add it to the previous layer's output.\n",
    "        return residual_output + feed_forward_output\n",
    "\n",
    "\n",
    "class DecoderStack(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The decoder stack consists of multiple decoder layers in sequence. Instead of a single decoder layer.\n",
    "    Each DecoderLayer applies masked self-attention, feed-forward, normalization, and residual connections.\n",
    "    The output of one layer becomes the input to the next.\n",
    "    This stacking enables the model to learn increasingly complex representations and dependencies in the sequence.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_dimension,\n",
    "            number_of_layers,\n",
    "            number_of_heads,\n",
    "            feed_forward_dimension,\n",
    "            dropout_rate,\n",
    "            max_sequence_length\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.number_of_layers = number_of_layers\n",
    "        self.number_of_heads = number_of_heads\n",
    "        self.feed_forward_dimension = feed_forward_dimension\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "\n",
    "        # Create the encoder layers\n",
    "        self.encoder_layers = torch.nn.ModuleList(\n",
    "            [DecoderLayer(embedding_dimension, number_of_heads, feed_forward_dimension, dropout_rate) for _ in\n",
    "             range(number_of_layers)])\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        decoder_outputs = x\n",
    "        for decoder_layer in self.encoder_layers:\n",
    "            decoder_outputs = decoder_layer(decoder_outputs, mask)\n",
    "\n",
    "        return decoder_outputs\n",
    "\n",
    "\n",
    "class LMHead(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch module for the language model head.\n",
    "    It’s the final layer in many language models that converts the processed token embeddings back into a distribution over the vocabulary. \n",
    "    This output can then be used to predict the next token in the sequence or generate probabilities over all possible tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    #Take two inputs: embedding_dimension: size of the embedding vectors for each token (e.g., 512, 768, etc.).\n",
    "    #number_of_tokens: size of the vocabulary (how many different tokens can be predicted).\n",
    "    #Create a linear layer self.linear that transforms vectors of size embedding_dimension to vectors of size number_of_tokens.\n",
    "    def __init__(self, embedding_dimension, number_of_tokens):\n",
    "        super().__init__()\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.number_of_tokens = number_of_tokens\n",
    "        self.linear = torch.nn.Linear(embedding_dimension, number_of_tokens)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Compute the language model head.\n",
    "        Input x:\n",
    "        A tensor of shape (batch_size, sequence_length, embedding_dimension).\n",
    "        This is the output from the decoder stack or any embedding layer representing the tokens.\n",
    "        Process:\n",
    "        Passes the input through the linear layer.\n",
    "        The linear layer independently projects each embedding vector (for each token in each sequence) into a vector of logits over the vocabulary.\n",
    "        Output:\n",
    "        A tensor of shape (batch_size, sequence_length, number_of_tokens).\n",
    "        For every token position, it gives a score (logit) for each token in the vocabulary.\n",
    "\n",
    "        x dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
    "        output dimensions are: (batch_size, sequence_length, number_of_tokens)\n",
    "        \"\"\"\n",
    "        # Compute the linear layer\n",
    "        # linear_output dimensions are: (batch_size, sequence_length, number_of_tokens)\n",
    "        linear_output = self.linear(x)\n",
    "\n",
    "        return linear_output\n",
    "\n",
    "\n",
    "class LanguageModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch module for a language model.The LanguageModel wraps the whole transformer decoder-based language modeling pipeline.\n",
    "    It embeds tokens, adds positional info, applies multiple decoder layers with self-attention and feed-forward networks, and finally predicts token logits.\n",
    "    Dropout, layer normalization, and masking are used to stabilize and regularize training.\n",
    "    Checkpoint methods help save/load trained models easily.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            number_of_tokens,  # The number of tokens in the vocabulary\n",
    "            max_sequence_length=512,  # The maximum sequence length to use for attention\n",
    "            embedding_dimension=512,  # The dimension of the token embeddings\n",
    "            number_of_layers=6,  # The number of decoder layers to use\n",
    "            number_of_heads=4,  # The number of attention heads to use\n",
    "            feed_forward_dimension=None,  # The dimension of the feed forward layer\n",
    "            dropout_rate=0.1  # The dropout rate to use\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.number_of_tokens = number_of_tokens\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.number_of_layers = number_of_layers\n",
    "        self.number_of_heads = number_of_heads\n",
    "\n",
    "        if feed_forward_dimension is None:\n",
    "            # GPT-2 paper uses 4 * embedding_dimension for the feed forward dimension\n",
    "            self.feed_forward_dimension = embedding_dimension * 4\n",
    "        else:\n",
    "            self.feed_forward_dimension = feed_forward_dimension\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # Create the token embedding layer\n",
    "        self.token_embedding = TokenEmbedding(embedding_dimension, number_of_tokens)\n",
    "\n",
    "        # Create the positional encoding layer\n",
    "        self.positional_encoding = PositionalEncoding(embedding_dimension, max_sequence_length)\n",
    "\n",
    "        # Create the normalization layer\n",
    "        self.layer_normalization = torch.nn.LayerNorm(embedding_dimension)\n",
    "\n",
    "        # Create the decoder stack\n",
    "        self.decoder = DecoderStack(\n",
    "            embedding_dimension=embedding_dimension,\n",
    "            number_of_layers=number_of_layers,\n",
    "            number_of_heads=number_of_heads,\n",
    "            feed_forward_dimension=self.feed_forward_dimension,\n",
    "            dropout_rate=dropout_rate,\n",
    "            max_sequence_length=max_sequence_length\n",
    "        )\n",
    "\n",
    "        # Create the language model head\n",
    "        self.lm_head = LMHead(embedding_dimension, number_of_tokens)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # Compute the token embeddings\n",
    "        # token_embeddings dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
    "        token_embeddings = self.token_embedding(x)\n",
    "\n",
    "        # Compute the positional encoding\n",
    "        # positional_encoding dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
    "        positional_encoding = self.positional_encoding(token_embeddings)\n",
    "\n",
    "        # Post embedding layer normalization\n",
    "        positional_encoding_normalized = self.layer_normalization(positional_encoding)\n",
    "\n",
    "        decoder_outputs = self.decoder(positional_encoding_normalized, mask)\n",
    "        lm_head_outputs = self.lm_head(decoder_outputs)\n",
    "\n",
    "        return lm_head_outputs\n",
    "\n",
    "    def save_checkpoint(self, path):\n",
    "        print(f'Saving checkpoint {path}')\n",
    "        torch.save({\n",
    "            'number_of_tokens': self.number_of_tokens,\n",
    "            'max_sequence_length': self.max_sequence_length,\n",
    "            'embedding_dimension': self.embedding_dimension,\n",
    "            'number_of_layers': self.number_of_layers,\n",
    "            'number_of_heads': self.number_of_heads,\n",
    "            'feed_forward_dimension': self.feed_forward_dimension,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "            'model_state_dict': self.state_dict()\n",
    "        }, path)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(path) -> 'LanguageModel':\n",
    "        checkpoint = torch.load(path)\n",
    "        model = LanguageModel(\n",
    "            number_of_tokens=checkpoint['number_of_tokens'],\n",
    "            max_sequence_length=checkpoint['max_sequence_length'],\n",
    "            embedding_dimension=checkpoint['embedding_dimension'],\n",
    "            number_of_layers=checkpoint['number_of_layers'],\n",
    "            number_of_heads=checkpoint['number_of_heads'],\n",
    "            feed_forward_dimension=checkpoint['feed_forward_dimension'],\n",
    "            dropout_rate=checkpoint['dropout_rate']\n",
    "        )\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        return model.to(get_device())\n",
    "\n",
    "\n",
    "class AutoregressiveWrapper(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch module that wraps a GPT model and makes it autoregressive.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gpt_model):\n",
    "        super().__init__()\n",
    "        self.model = gpt_model\n",
    "        self.max_sequence_length = self.model.max_sequence_length\n",
    "\n",
    "    #Input x is the full sequence of token IDs including the next token to predict.\n",
    "    #The sequence is split into two parts:\n",
    "    #inp: All tokens except the last (x[:, :-1]), which serve as the input context.\n",
    "    #target: All tokens except the first (x[:, 1:]), which are the \"true\" tokens to predict at each step.\n",
    "    #The mask is adjusted accordingly to ignore the last token’s mask, since we’re predicting it.\n",
    "    #Call the underlying GPT model on inp and its mask.\n",
    "    #Return the model's output logits (predictions for each input token) and the target tokens for loss computation.\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Autoregressive forward pass\n",
    "        \"\"\"\n",
    "        inp, target = x[:, :-1], x[:, 1:]\n",
    "        mask = mask[:, :-1]\n",
    "\n",
    "        output = self.model(inp, mask)\n",
    "        return output, target\n",
    "    # Given a sequence x and mask, compute the probability distribution of the next token.\n",
    "    # Call the model on the entire sequence.\n",
    "    # Extract the logits of the last token ([:, -1]), which correspond to the next-token prediction.\n",
    "    # Optionally applie temperature scaling:\n",
    "    # Lower temperature (<1) sharpens probabilities (more confident),\n",
    "    # Higher temperature (>1) softens them (more random).\n",
    "    # Convert logits to probabilities via softmax.\n",
    "    # Return the probability distribution over the vocabulary for the next token.\n",
    "    def next_token_probabilities(self, x, mask, temperature=1.0):\n",
    "        \"\"\"\n",
    "        Calculate the token probabilities for the next token in the sequence.\n",
    "        \"\"\"\n",
    "        logits = self.model(x, mask)[:, -1]\n",
    "\n",
    "        # Apply temperature\n",
    "        if temperature != 1.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "        # Apply the softmax\n",
    "        probabilities = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        return probabilities\n",
    "\n",
    "    def save_checkpoint(self, path):\n",
    "        self.model.save_checkpoint(path)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(path) -> 'AutoregressiveWrapper':\n",
    "        model = LanguageModel.load_checkpoint(path)\n",
    "        return AutoregressiveWrapper(model).to(get_device())\n",
    "\n",
    "\n",
    "class Tokenizer:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dictionary = {}\n",
    "        self.reverse_dictionary = {}\n",
    "\n",
    "        # Add the padding token\n",
    "        self.__add_to_dict('<pad>')\n",
    "\n",
    "        # Add characters and numbers to the dictionary\n",
    "        for i in range(10):\n",
    "            self.__add_to_dict(str(i))\n",
    "        for i in range(26):\n",
    "            self.__add_to_dict(chr(ord('a') + i))\n",
    "\n",
    "        # Add space and punctuation to the dictionary\n",
    "        self.__add_to_dict('.')\n",
    "        self.__add_to_dict(' ')\n",
    "\n",
    "    def __add_to_dict(self, character):\n",
    "        if character not in self.dictionary:\n",
    "            self.dictionary[character] = len(self.dictionary)\n",
    "            self.reverse_dictionary[self.dictionary[character]] = character\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        return [self.dictionary[c] for c in text]\n",
    "\n",
    "    def character_to_token(self, character):\n",
    "        return self.dictionary[character]\n",
    "\n",
    "    def token_to_character(self, token):\n",
    "        return self.reverse_dictionary[token]\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.dictionary)\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    # Handle training loop for the model.\n",
    "    # Prepare batches, converts sequences to tensors, applies masks for padding tokens.\n",
    "    # Run forward pass, computes loss, does backpropagation with gradient clipping.\n",
    "    # Track and print loss per epoch.\n",
    "    def __init__(self, model, tokenizer: Tokenizer, optimizer=None):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        if optimizer is None:\n",
    "            self.optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "        else:\n",
    "            self.optimizer = optimizer\n",
    "        self.tokenizer = tokenizer\n",
    "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def train(self, data: List[str], epochs, batch_size):\n",
    "        loss_per_epoch = []\n",
    "        for epoch in range(epochs):\n",
    "            losses = []\n",
    "\n",
    "            # Shuffle the sequences\n",
    "            random.shuffle(data)\n",
    "\n",
    "            # Create batches of sequences and their respective mask.\n",
    "            batches = []\n",
    "            for i in range(0, len(data), batch_size):\n",
    "                sequence_tensor = torch.tensor(data[i: i + batch_size], dtype=torch.long)\n",
    "\n",
    "                # Create the mask tensor for the batch, where 1 means the token is not a padding token\n",
    "                mask_tensor = torch.ones_like(sequence_tensor)\n",
    "                mask_tensor[sequence_tensor == self.tokenizer.character_to_token('<pad>')] = 0\n",
    "\n",
    "                batches.append((sequence_tensor, mask_tensor))\n",
    "\n",
    "            # Train the model on each batch\n",
    "            for batch in batches:\n",
    "                self.model.train()\n",
    "\n",
    "                # Create the input and mask tensors\n",
    "                input_tensor = torch.zeros((batch_size, self.model.max_sequence_length + 1), dtype=torch.long)\n",
    "                mask_tensor = torch.zeros((batch_size, self.model.max_sequence_length + 1), dtype=torch.long)\n",
    "\n",
    "                for i, input_entry in enumerate(batch[0]):\n",
    "                    input_tensor[i] = input_entry\n",
    "\n",
    "                for i, mask_entry in enumerate(batch[1]):\n",
    "                    mask_tensor[i] = mask_entry\n",
    "\n",
    "                # Compute the model output\n",
    "                model_output, target = self.model.forward(\n",
    "                    x=input_tensor.to(get_device()),\n",
    "                    mask=mask_tensor.to(get_device())\n",
    "                )\n",
    "\n",
    "                # Compute the losses\n",
    "                # The loss is computed on the model output and the target\n",
    "                loss = self.loss_function(model_output.transpose(1, 2), target)\n",
    "                # loss = self.loss_function(model_output[:, -1, :], target[:, -1])\n",
    "\n",
    "                # Backpropagate the loss.\n",
    "                loss.backward()\n",
    "\n",
    "                # Clip the gradients. This is used to prevent exploding gradients.\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.5)\n",
    "\n",
    "                # Update the model parameters. This is done by taking a step in the direction of the gradient.\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # Reset the gradients. This is done so that the gradients from the previous batch\n",
    "                # are not used in the next step.\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Append the loss to the list of losses, so that the average loss can be computed for this epoch.\n",
    "                losses.append(loss.item())\n",
    "\n",
    "            # Print the loss\n",
    "            epoch_loss = np.average(losses)\n",
    "            loss_per_epoch.append(epoch_loss)\n",
    "            print('Epoch:', epoch, 'Loss:', epoch_loss)\n",
    "\n",
    "        return loss_per_epoch\n",
    "\n",
    "\n",
    "class Generator:\n",
    "    # Generate new text tokens from the trained model.\n",
    "    # Start from an optional prompt or padding token.\n",
    "    # Use autoregressive sampling:\n",
    "    # Predict next token probabilities,\n",
    "    # Sample one token,\n",
    "    # Append it to sequence,\n",
    "    # Stop on EOS token or max tokens.\n",
    "    # Convert tokens back to characters for output text.\n",
    "    def __init__(\n",
    "            self,\n",
    "            model,\n",
    "            tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def generate(\n",
    "            self,\n",
    "            max_tokens_to_generate: int,\n",
    "            prompt: str = None,\n",
    "            temperature: float = 1.0,\n",
    "            eos_token: int = None,\n",
    "            padding_token: int = 0):\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        if prompt is None:\n",
    "            start_tokens = [self.tokenizer.character_to_token(padding_token)]\n",
    "        else:\n",
    "            start_tokens = self.tokenizer.tokenize(prompt)\n",
    "\n",
    "        input_tensor = torch.tensor(\n",
    "            pad_left(\n",
    "                sequence=start_tokens,\n",
    "                final_length=self.model.max_sequence_length + 1,\n",
    "                padding_token=padding_token\n",
    "            ),\n",
    "            dtype=torch.long\n",
    "        ).to(get_device())\n",
    "\n",
    "        num_dims = len(input_tensor.shape)\n",
    "\n",
    "        if num_dims == 1:\n",
    "            input_tensor = input_tensor[None, :]\n",
    "\n",
    "        out = input_tensor\n",
    "        for _ in range(max_tokens_to_generate):\n",
    "\n",
    "            x = out[:, -self.model.max_sequence_length:]\n",
    "\n",
    "            mask = torch.ones_like(x)\n",
    "            mask[x == padding_token] = 0\n",
    "\n",
    "            # Compute the next token probabilities\n",
    "            next_token_probabilities = self.model.next_token_probabilities(\n",
    "                x=x,\n",
    "                temperature=temperature,\n",
    "                mask=mask\n",
    "            )\n",
    "\n",
    "            # Sample the next token from the probability distribution\n",
    "            next_token = torch.multinomial(next_token_probabilities, num_samples=1)\n",
    "\n",
    "            # Append the next token to the output\n",
    "            out = torch.cat([out, next_token], dim=1)\n",
    "\n",
    "            # If the end of sequence token is reached, stop generating tokens\n",
    "            if eos_token is not None and next_token == eos_token:\n",
    "                break\n",
    "\n",
    "        generated_tokens = out[0].tolist()\n",
    "        return ''.join([self.tokenizer.token_to_character(token) for token in generated_tokens])\n",
    "\n",
    "def create_training_sequences(max_sequence_length, tokenized_training_data):\n",
    "    # Create sequences of length max_sequence_length + 1\n",
    "    # The last token of each sequence is the target token\n",
    "    sequences = []\n",
    "    for i in range(0, len(tokenized_training_data) - max_sequence_length - 1):\n",
    "        sequences.append(tokenized_training_data[i: i + max_sequence_length + 1])\n",
    "    return sequences\n",
    "\n",
    "\n",
    "def tokenize_and_pad_training_data(max_sequence_length, tokenizer, training_data):\n",
    "    # Tokenize the training data\n",
    "    tokenized_training_data = tokenizer.tokenize(training_data)\n",
    "    for _ in range(max_sequence_length):\n",
    "        # Prepend padding tokens\n",
    "        tokenized_training_data.insert(0, tokenizer.character_to_token('<pad>'))\n",
    "    return tokenized_training_data\n",
    "\n",
    "# Set up tokenizer, model, and training data.\n",
    "# Tokenize and prepare sequences with padding.\n",
    "# Train the model for 120 epochs.\n",
    "# Plot loss on log scale.\n",
    "# Save the model.\n",
    "# Generate 400 characters starting from \"cats\" prompt and prints generated text.\n",
    "class Runner(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def run(self):\n",
    "        # Create the tokenizer\n",
    "        tokenizer = Tokenizer()\n",
    "\n",
    "        embedding_dimension = 256\n",
    "        max_sequence_length = 20\n",
    "        number_of_tokens = tokenizer.size()\n",
    "\n",
    "        # Create the model\n",
    "        model = AutoregressiveWrapper(LanguageModel(\n",
    "            embedding_dimension=embedding_dimension,\n",
    "            number_of_tokens=number_of_tokens,\n",
    "            number_of_heads=4,\n",
    "            number_of_layers=3,\n",
    "            dropout_rate=0.1,\n",
    "            max_sequence_length=max_sequence_length\n",
    "        )).to(get_device())\n",
    "\n",
    "        # Create the training data\n",
    "        training_data = '. '.join([\n",
    "            'cats rule the world',\n",
    "            'dogs are the best',\n",
    "            'elephants have long trunks',\n",
    "            'monkeys like bananas',\n",
    "            'pandas eat bamboo',\n",
    "            'tigers are dangerous',\n",
    "            'zebras have stripes',\n",
    "            'lions are the kings of the savannah',\n",
    "            'giraffes have long necks',\n",
    "            'hippos are big and scary',\n",
    "            'rhinos have horns',\n",
    "            'penguins live in the arctic',\n",
    "            'polar bears are white'\n",
    "        ])\n",
    "\n",
    "        tokenized_and_padded_training_data = tokenize_and_pad_training_data(max_sequence_length, tokenizer, training_data)\n",
    "        sequences = create_training_sequences(max_sequence_length, tokenized_and_padded_training_data)\n",
    "\n",
    "        # Train the model\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "        trainer = Trainer(model, tokenizer, optimizer)\n",
    "        loss_per_epoch = trainer.train(sequences, epochs=120, batch_size=16)\n",
    "\n",
    "        # Plot the loss per epoch in log scale\n",
    "        plt.plot(loss_per_epoch)\n",
    "        plt.yscale('log')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.show()\n",
    "\n",
    "        model.save_checkpoint('./trained_model')\n",
    "\n",
    "        # Generate text\n",
    "        max_tokens_to_generate = 400\n",
    "        generator = Generator(model, tokenizer)\n",
    "        generated_text = generator.generate(\n",
    "            max_tokens_to_generate=max_tokens_to_generate,\n",
    "            prompt=\"cats\",\n",
    "            padding_token=tokenizer.character_to_token('<pad>')\n",
    "        )\n",
    "        print(generated_text.replace('<pad>', ''))\n",
    "\n",
    "\n",
    "def pad_left(sequence, final_length, padding_token):\n",
    "    return [padding_token] * (final_length - len(sequence)) + sequence\n",
    "\n",
    "\n",
    "Runner().run()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
