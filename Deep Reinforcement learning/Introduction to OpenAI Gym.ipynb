{"cells":[{"cell_type":"markdown","metadata":{"id":"ieNQPZ7Ub79I"},"source":["# **Steps for Accessing the Colab:**\n","\n","\n","1.   Login to your BITS Elearn Portal\n","2.   Go to DRL course Home page\n","3. Go to Lectures -> Webinar Materials\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pLEU8UyJb79J"},"source":["# **Problem Description**\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gkrRC40ab79J"},"source":["# **Reinforcement Learning (RL) and OpenAI Gym**\n","\n","*   The set of tasks that can be solved using the means of\n","reinforcement learning tools is quite broad, and each of these tasks may\n","have its own code implementation.\n","*   At the same time, various RL techniques\n","can be applied to any RL problem.\n","*   But at this point, an applicability\n","problem may arise since each task can have its own implementation, and it\n","can be quite challenging to implement a specific RL algorithm in a\n","particular situation.\n","* Gym solves this problem by unifying all reinforcement\n","learning tasks.\n","* OpenAI Gym is a free Python toolkit that provides developers with an environment for developing and testing learning agents for deep learning models.\n","\n","# **Benefits of Gym**\n","\n","* Gym unifies the process of testing solutions to reinforcement learning\n","problems.\n","* Each RL problem can have its own unique solution, which will\n","allow the agent to maximize rewards.\n","* It is often helpful to test several predesigned\n","RL algorithms and see which one performs the best. Such brute\n","force technique can provide a useful direction for developing your own\n","solution or possibly applying an existing one.\n","* The Gym toolkit offers a\n","standard interface for all RL problems, which allows you to test various\n","solution production-ready algorithms."]},{"cell_type":"markdown","metadata":{"id":"9Z57aOoGb79K"},"source":[]},{"cell_type":"markdown","metadata":{"id":"SAjpdRyQb79L"},"source":["# ***Key Concept of RL***\n","\n","![img3.png](data:image/png;base64,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)"]},{"cell_type":"markdown","metadata":{"id":"S9tcQGoJb79L"},"source":["* **Agent** is a decision-maker who defines what action to take.\n","  **Examples:** Self-driving car, chess player, stock trading robot\n","* **Action** is a concrete act in a surrounding environment that is taken by the\n","agent. **Examples:** Turn car left, move chess pawn one cell forward, sell all\n","assets\n","* **Environment** is a problem context that the agent cooperates with. **Examples:** Car track, chess board, stock market\n","* **State** is a position of the agent in the environment. **Examples:** Car coordinates on the track and its speed, arrangement of pieces on the chessboard, price of assets\n","* **Reward** is a numerical value returned by an environment as the reaction\n","to the agent's action. **Example:** To reach a goal on the car without any accidents, to win chess play, to earn more money"]},{"cell_type":"markdown","metadata":{"id":"kZ9ffz45b79M"},"source":["# **Execution**\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EcpEex2yb79M"},"source":["# **Working With Gym**"]},{"cell_type":"markdown","metadata":{"id":"U_xAEvRPb79M"},"source":[]},{"cell_type":"markdown","metadata":{"id":"KtnKj8USb79M"},"source":["Step 1: **Gym Installation:** Install gym and give instruction for the output to be displayed in standard output"]},{"cell_type":"code","source":["!pip install gymnasium"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8PRXEkJFOv1_","executionInfo":{"status":"ok","timestamp":1736143745323,"user_tz":-330,"elapsed":5769,"user":{"displayName":"Divya K","userId":"07514915955852652590"}},"outputId":"b1ff66ac-43c1-4ce5-bb24-43bd6c81b8e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"output_type":"stream","name":"stdout","text":["Collecting gymnasium\n","  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (3.1.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n","Collecting farama-notifications>=0.0.1 (from gymnasium)\n","  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n","Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Installing collected packages: farama-notifications, gymnasium\n","Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0\n"]}]},{"cell_type":"code","source":["!pip install pygame"],"metadata":{"id":"QTOfhDg0ngZf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z0XDjoUcb79O"},"source":[]},{"cell_type":"markdown","metadata":{"id":"c5mc5GUkb79O"},"source":["***To view the existing Environments in Gym***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kU5GaSKLb79O","outputId":"cdcac4c1-0185-4d0e-f0f9-e44fe04b90f5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736143778426,"user_tz":-330,"elapsed":381,"user":{"displayName":"Divya K","userId":"07514915955852652590"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["CartPole-v0\n","CartPole-v1\n","MountainCar-v0\n","MountainCarContinuous-v0\n","Pendulum-v1\n","Acrobot-v1\n","phys2d/CartPole-v0\n","phys2d/CartPole-v1\n","phys2d/Pendulum-v0\n","LunarLander-v3\n","LunarLanderContinuous-v3\n","BipedalWalker-v3\n","BipedalWalkerHardcore-v3\n","CarRacing-v3\n","Blackjack-v1\n","FrozenLake-v1\n","FrozenLake8x8-v1\n","CliffWalking-v0\n","Taxi-v3\n","tabular/Blackjack-v0\n","tabular/CliffWalking-v0\n","Reacher-v2\n","Reacher-v4\n","Reacher-v5\n","Pusher-v2\n","Pusher-v4\n","Pusher-v5\n","InvertedPendulum-v2\n","InvertedPendulum-v4\n","InvertedPendulum-v5\n","InvertedDoublePendulum-v2\n","InvertedDoublePendulum-v4\n","InvertedDoublePendulum-v5\n","HalfCheetah-v2\n","HalfCheetah-v3\n","HalfCheetah-v4\n","HalfCheetah-v5\n","Hopper-v2\n","Hopper-v3\n","Hopper-v4\n","Hopper-v5\n","Swimmer-v2\n","Swimmer-v3\n","Swimmer-v4\n","Swimmer-v5\n","Walker2d-v2\n","Walker2d-v3\n","Walker2d-v4\n","Walker2d-v5\n","Ant-v2\n","Ant-v3\n","Ant-v4\n","Ant-v5\n","Humanoid-v2\n","Humanoid-v3\n","Humanoid-v4\n","Humanoid-v5\n","HumanoidStandup-v2\n","HumanoidStandup-v4\n","HumanoidStandup-v5\n","GymV21Environment-v0\n","GymV26Environment-v0\n"]}],"source":["from gymnasium import envs\n","for e in envs.registry.values():\n","    print(e.id)"]},{"cell_type":"markdown","metadata":{"id":"o2xFKcTQb79O"},"source":["***To realise the working of RL and its concepts, we will see how it is implemented in real time using Gym.***"]},{"cell_type":"markdown","metadata":{"id":"EqAAsqdbb79P"},"source":["The Mountain Car problem consists of a car placed stochastically at the bottom of a sinusoidal valley, with the only possible actions being the accelerations that can be applied to the car in either direction. The goal of the MDP is to strategically accelerate the car to reach the goal state on top of the right hill."]},{"cell_type":"markdown","metadata":{"id":"Sq6QAOySb79P"},"source":["![image.png](attachment:image.png)"]},{"cell_type":"markdown","metadata":{"id":"dk2mqk7hb79P"},"source":["Step 2: Import the sleep function from the time module, allowing for pauses in the code execution.\n","\n","---\n","\n","\n","Step 3: Import the Gym library, which provides a collection of environments to test reinforcement learning algorithms.\n","\n","---\n","\n","\n","Step 4: Import the random module, used for generating random numbers."]},{"cell_type":"markdown","metadata":{"id":"YwzzKmIjb79P"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uMMOe-RIb79P","executionInfo":{"status":"ok","timestamp":1736143805917,"user_tz":-330,"elapsed":392,"user":{"displayName":"Divya K","userId":"07514915955852652590"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"46be71bd-889d-4c4e-821c-67bfac047dc3"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["from time import sleep\n","import gymnasium as gym\n","import random"]},{"cell_type":"markdown","metadata":{"id":"aZR-icefb79P"},"source":["Step 5: Environment Initialization - Create an instance of the Mountain car environment named env using Gym's make function. The 'MountainCar-v0' environment simulates a car climbing the mountain, with the goal of making the car to reach the goal at the right side of the mountain hill."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rXzRQDRCb79P"},"outputs":[],"source":["env = gym.make('MountainCar-v0')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AtNWivpcb79Q","outputId":"a9c5d622-b5ed-42e7-a963-d22da5aa0e13","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736143812733,"user_tz":-330,"elapsed":362,"user":{"displayName":"Divya K","userId":"07514915955852652590"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gymnasium/envs/classic_control/mountain_car.py:179: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"MountainCar-v0\", render_mode=\"rgb_array\")\u001b[0m\n","  gym.logger.warn(\n"]}],"source":["env.reset()\n","env.render()"]},{"cell_type":"markdown","metadata":{"id":"tZ86_VDIb79Q"},"source":["Step 6: Initialize the seed variable.\n","\n","\n","---\n","\n","Step 7: Set the seed for the random number generator in the random module to ensure reproducibility. In other words, using this parameter makes sure that anyone who re-runs your code will get the exact same outputs.\n","\n","---\n","\n","Step 8: Set the seed for Gym's environment to maintain consistency in the environment's behavior across runs.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RiKzzb0Vb79Q"},"outputs":[],"source":["seed = 0\n","random.seed(seed)"]},{"cell_type":"markdown","metadata":{"id":"YBSgzNAgb79Q"},"source":["Step 9: Print the action space of the Mountain car environment, which in this case, has three possible actions: accelerate to left or accelerate to right or don't accelerate.\n","\n","---\n","\n","0 - Accelerate to left, 1 - Don't accelerate and 2 - Accelerate to right\n","\n","---\n","\n","The data returned by the mountain car environment after an action is taken is shown in the following table.\n","![image-2.png](attachment:image-2.png)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hpob4c_5b79R","outputId":"38371d14-761f-4bde-b3c1-64f89b277d14","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736143820960,"user_tz":-330,"elapsed":362,"user":{"displayName":"Divya K","userId":"07514915955852652590"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Action Space: Discrete(3)\n"]}],"source":["print(f'Action Space: {env.action_space}')"]},{"cell_type":"markdown","metadata":{"id":"zXwrRYybb79S"},"source":["Action Spaces:\n","\n","![image.png](attachment:image.png)\n","\n","State Spaces:\n","\n","![image-2.png](attachment:image-2.png)\n","\n","The episode ends if either of the following happens:\n","\n","Termination: The position of the car is greater than or equal to 0.5 (the goal position on top of the right hill)\n","\n","Truncation: The length of the episode is 200."]},{"cell_type":"markdown","metadata":{"id":"52W4hycHb79S"},"source":["Step 10: Set the number of episodes (iterations) for the agent to interact with the environment."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rx3lOPMrb79S"},"outputs":[],"source":["episodes = 10"]},{"cell_type":"markdown","metadata":{"id":"W6l6ZkMDb79S"},"source":["Step 11: Initiate a loop to run a specified number of episodes.\n","\n","---\n","\n","Step 12: Reset the environment to its initial state at the beginning of each episode and captures the initial state.\n","\n","---\n","\n","Step 13: Initialize the variable reward_sum to keep track of the total rewards obtained in an episode.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p7tukP_5b79S"},"outputs":[],"source":["for i in range(episodes):\n","    init_state = env.reset()\n","    reward_sum = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OAGfAyCHb79T","outputId":"a59f8a51-7388-43f9-fe93-edd18e60a489","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735893346850,"user_tz":-330,"elapsed":3,"user":{"displayName":"Pooja Harde","userId":"16707800049251750964"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.4154488,  0.       ], dtype=float32)"]},"metadata":{},"execution_count":10}],"source":["init_state"]},{"cell_type":"markdown","metadata":{"id":"GPdOVZhqb79T"},"source":["Step 14: Start an infinite loop for each episode until a termination condition (done) is reached.\n","\n","---\n","\n","Step 15: Render the environment, allowing you to see the simulation (visual representation) of the Mountain car.\n","\n","---\n","\n","Step 16: Choose a random action (0 or 1 or 2) for the agent (accelerate left or don't accelerate or accelerate right).\n","\n","---\n","\n","Step 17: Execute the chosen action in the environment and receive the next state, reward obtained, termination status (done), and additional debug information.\n","\n","---\n","\n","Step 18: Update the total reward obtained in the current episode.\n","\n","---\n","\n","Step 19: Introduce a short delay for visualization purposes.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BaAqSlCvb79T","outputId":"656d2730-c700-43e6-f68d-ce6cad726dcc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736143615332,"user_tz":-330,"elapsed":7138,"user":{"displayName":"Divya K","userId":"07514915955852652590"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/core.py:49: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n","If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n","  if not isinstance(terminated, (bool, np.bool8)):\n"]},{"output_type":"stream","name":"stdout","text":["Reward_sum is -1.0\n","Reward_sum is -2.0\n","Reward_sum is -3.0\n","Reward_sum is -4.0\n","Reward_sum is -5.0\n","Reward_sum is -6.0\n","Reward_sum is -7.0\n","Reward_sum is -8.0\n","Reward_sum is -9.0\n","Reward_sum is -10.0\n","Reward_sum is -11.0\n","Reward_sum is -12.0\n","Reward_sum is -13.0\n","Reward_sum is -14.0\n","Reward_sum is -15.0\n","Reward_sum is -16.0\n","Reward_sum is -17.0\n","Reward_sum is -18.0\n","Reward_sum is -19.0\n","Reward_sum is -20.0\n","Reward_sum is -21.0\n","Reward_sum is -22.0\n","Reward_sum is -23.0\n","Reward_sum is -24.0\n","Reward_sum is -25.0\n","Reward_sum is -26.0\n","Reward_sum is -27.0\n","Reward_sum is -28.0\n","Reward_sum is -29.0\n","Reward_sum is -30.0\n","Reward_sum is -31.0\n","Reward_sum is -32.0\n","Reward_sum is -33.0\n","Reward_sum is -34.0\n","Reward_sum is -35.0\n","Reward_sum is -36.0\n","Reward_sum is -37.0\n","Reward_sum is -38.0\n","Reward_sum is -39.0\n","Reward_sum is -40.0\n","Reward_sum is -41.0\n","Reward_sum is -42.0\n","Reward_sum is -43.0\n","Reward_sum is -44.0\n","Reward_sum is -45.0\n","Reward_sum is -46.0\n","Reward_sum is -47.0\n","Reward_sum is -48.0\n","Reward_sum is -49.0\n","Reward_sum is -50.0\n","Reward_sum is -51.0\n","Reward_sum is -52.0\n","Reward_sum is -53.0\n","Reward_sum is -54.0\n","Reward_sum is -55.0\n","Reward_sum is -56.0\n","Reward_sum is -57.0\n","Reward_sum is -58.0\n","Reward_sum is -59.0\n","Reward_sum is -60.0\n","Reward_sum is -61.0\n","Reward_sum is -62.0\n","Reward_sum is -63.0\n","Reward_sum is -64.0\n","Reward_sum is -65.0\n","Reward_sum is -66.0\n","Reward_sum is -67.0\n","Reward_sum is -68.0\n","Reward_sum is -69.0\n","Reward_sum is -70.0\n","Reward_sum is -71.0\n","Reward_sum is -72.0\n","Reward_sum is -73.0\n","Reward_sum is -74.0\n","Reward_sum is -75.0\n","Reward_sum is -76.0\n","Reward_sum is -77.0\n","Reward_sum is -78.0\n","Reward_sum is -79.0\n","Reward_sum is -80.0\n","Reward_sum is -81.0\n","Reward_sum is -82.0\n","Reward_sum is -83.0\n","Reward_sum is -84.0\n","Reward_sum is -85.0\n","Reward_sum is -86.0\n","Reward_sum is -87.0\n","Reward_sum is -88.0\n","Reward_sum is -89.0\n","Reward_sum is -90.0\n","Reward_sum is -91.0\n","Reward_sum is -92.0\n","Reward_sum is -93.0\n","Reward_sum is -94.0\n","Reward_sum is -95.0\n","Reward_sum is -96.0\n","Reward_sum is -97.0\n","Reward_sum is -98.0\n","Reward_sum is -99.0\n","Reward_sum is -100.0\n","Reward_sum is -101.0\n","Reward_sum is -102.0\n","Reward_sum is -103.0\n","Reward_sum is -104.0\n","Reward_sum is -105.0\n","Reward_sum is -106.0\n","Reward_sum is -107.0\n","Reward_sum is -108.0\n","Reward_sum is -109.0\n","Reward_sum is -110.0\n","Reward_sum is -111.0\n","Reward_sum is -112.0\n","Reward_sum is -113.0\n","Reward_sum is -114.0\n","Reward_sum is -115.0\n","Reward_sum is -116.0\n","Reward_sum is -117.0\n","Reward_sum is -118.0\n","Reward_sum is -119.0\n","Reward_sum is -120.0\n","Reward_sum is -121.0\n","Reward_sum is -122.0\n","Reward_sum is -123.0\n","Reward_sum is -124.0\n","Reward_sum is -125.0\n","Reward_sum is -126.0\n","Reward_sum is -127.0\n","Reward_sum is -128.0\n","Reward_sum is -129.0\n","Reward_sum is -130.0\n","Reward_sum is -131.0\n","Reward_sum is -132.0\n","Reward_sum is -133.0\n","Reward_sum is -134.0\n","Reward_sum is -135.0\n","Reward_sum is -136.0\n","Reward_sum is -137.0\n","Reward_sum is -138.0\n","Reward_sum is -139.0\n","Reward_sum is -140.0\n","Reward_sum is -141.0\n","Reward_sum is -142.0\n","Reward_sum is -143.0\n","Reward_sum is -144.0\n","Reward_sum is -145.0\n","Reward_sum is -146.0\n","Reward_sum is -147.0\n","Reward_sum is -148.0\n","Reward_sum is -149.0\n","Reward_sum is -150.0\n","Reward_sum is -151.0\n","Reward_sum is -152.0\n","Reward_sum is -153.0\n","Reward_sum is -154.0\n","Reward_sum is -155.0\n","Reward_sum is -156.0\n","Reward_sum is -157.0\n","Reward_sum is -158.0\n","Reward_sum is -159.0\n","Reward_sum is -160.0\n","Reward_sum is -161.0\n","Reward_sum is -162.0\n","Reward_sum is -163.0\n","Reward_sum is -164.0\n","Reward_sum is -165.0\n","Reward_sum is -166.0\n","Reward_sum is -167.0\n","Reward_sum is -168.0\n","Reward_sum is -169.0\n","Reward_sum is -170.0\n","Reward_sum is -171.0\n","Reward_sum is -172.0\n","Reward_sum is -173.0\n","Reward_sum is -174.0\n","Reward_sum is -175.0\n","Reward_sum is -176.0\n","Reward_sum is -177.0\n","Reward_sum is -178.0\n","Reward_sum is -179.0\n","Reward_sum is -180.0\n","Reward_sum is -181.0\n","Reward_sum is -182.0\n","Reward_sum is -183.0\n","Reward_sum is -184.0\n","Reward_sum is -185.0\n","Reward_sum is -186.0\n","Reward_sum is -187.0\n","Reward_sum is -188.0\n","Reward_sum is -189.0\n","Reward_sum is -190.0\n","Reward_sum is -191.0\n","Reward_sum is -192.0\n","Reward_sum is -193.0\n","Reward_sum is -194.0\n","Reward_sum is -195.0\n","Reward_sum is -196.0\n","Reward_sum is -197.0\n","Reward_sum is -198.0\n","Reward_sum is -199.0\n","Episode ended with total reward: -200.0\n"]}],"source":["reward_sum=0\n","while True:\n","    env.render()\n","    random_action = random.randint(0, 2)\n","    state, reward, done,truncated = env.step(random_action)\n","    reward_sum += reward\n","    if done or truncated:\n","        print(f\"Episode ended with total reward: {reward_sum}\")\n","        break\n","    print('Reward_sum is', reward_sum)\n","    sleep(.01)"]},{"cell_type":"markdown","metadata":{"id":"Jpm2IhrIb79T"},"source":["Step 20: Check if the episode is done (the car has reached the goal or the maximum number of steps is reached).\n","\n","---\n","\n","Step 21: Print the total reward obtained in the current episode.\n","\n","---\n","\n","Step 22: Pause execution briefly before starting the next episode for visualization purposes.\n","\n","---\n","\n","Step 23: Break out of the current episode loop once the episode is finished.\n"]},{"cell_type":"markdown","metadata":{"id":"35HeoMckb79U"},"source":["Step 24: Close the environment once all episodes are completed."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQe7IAU2b79X","outputId":"c4eee4c8-d702-4550-f363-85c34af89326","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736143914500,"user_tz":-330,"elapsed":1261,"user":{"displayName":"Divya K","userId":"07514915955852652590"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"output_type":"stream","name":"stdout","text":["Action Space: Discrete(3)\n","Observation Space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n","Action Space: Discrete(3)\n","Observation Space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n","Action Space: Discrete(3)\n","Observation Space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n","Action Space: Discrete(3)\n","Observation Space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n","Action Space: Discrete(3)\n","Observation Space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n","Action Space: Discrete(3)\n","Observation Space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n","Action Space: Discrete(3)\n","Observation Space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n","Action Space: Discrete(3)\n","Observation Space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n","Action Space: Discrete(3)\n","Observation Space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n","Action Space: Discrete(3)\n","Observation Space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n","Action Space: Discrete(3)\n","Observation Space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n"]}],"source":["from time import sleep\n","import gymnasium as gym\n","import random\n","env = gym.make('MountainCar-v0', render_mode='human')\n","\n","seed = 0\n","random.seed(seed)\n","\n","print(f'Action Space: {env.action_space}')\n","print(f'Observation Space: {env.observation_space}')\n","\n","episodes = 10\n","reward_sum = 0\n","for i in range(episodes):\n","    init_state = env.reset()\n","    env.render()\n","    random_action = random.randint(0, 2)\n","    state, reward,truncated,done,info = env.step(random_action)\n","\n","    print(f'Action Space: {env.action_space}')\n","    print(f'Observation Space: {env.observation_space}')\n","\n","    reward_sum += reward\n","    sleep(.01)\n","    if done:\n","        print(f'Episode {i} reward: {reward_sum}')\n","        sleep(1)\n","        break\n","env.close()"]},{"cell_type":"markdown","metadata":{"id":"fFT3TgH2b79X"},"source":["***Random movements cannot make the car reach the goal soon.\n","Balancing is one of the most challenging tasks in robotics.***\n","\n","---\n","\n","***The key is understanding the dynamics: the car cannot reach the top directly—it needs to build momentum by moving back and forth. We need to build the momentum to climb the hill. If the car is moving left (velocity < 0), apply a leftward force (action = 0) to maximize momentum in that direction.If the car is moving right (velocity >= 0), apply a rightward force (action = 2) to boost momentum in the forward direction.***\n","\n","---\n","\n","***So, let's try to implement this idea. We accelerate the car to the left if the velocity is negative, and we accelerate the car to the right if the velocity\n","is positive***"]},{"cell_type":"markdown","metadata":{"id":"dttPNiobb79Y"},"source":["Here, we determine the action based on the current state of the environment. If the velocity (state[1]) is negative, it chooses action 0 (accelerate left);If the velocity (state[1]) is 0 or positive, it chooses action 2 (accelerate right);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o4uA3gUZb79Y","outputId":"032c4fdf-f4d3-4cf7-8389-ff3c56d726d5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736143938666,"user_tz":-330,"elapsed":8374,"user":{"displayName":"Divya K","userId":"07514915955852652590"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"output_type":"stream","name":"stdout","text":["Action Space: Discrete(3)\n","Observation Space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n","[-0.46410716  0.        ]\n","Position: -0.464, Velocity: 0.000, Action: 2,Reward: -1.0\n","Reward sum: -1.0\n","Position: -0.464, Velocity: 0.001, Action: 2,Reward: -1.0\n","Reward sum: -2.0\n","Position: -0.462, Velocity: 0.001, Action: 2,Reward: -1.0\n","Reward sum: -3.0\n","Position: -0.461, Velocity: 0.002, Action: 2,Reward: -1.0\n","Reward sum: -4.0\n","Position: -0.459, Velocity: 0.002, Action: 2,Reward: -1.0\n","Reward sum: -5.0\n","Position: -0.456, Velocity: 0.003, Action: 2,Reward: -1.0\n","Reward sum: -6.0\n","Position: -0.453, Velocity: 0.003, Action: 2,Reward: -1.0\n","Reward sum: -7.0\n","Position: -0.449, Velocity: 0.004, Action: 2,Reward: -1.0\n","Reward sum: -8.0\n","Position: -0.445, Velocity: 0.004, Action: 2,Reward: -1.0\n","Reward sum: -9.0\n","Position: -0.440, Velocity: 0.005, Action: 2,Reward: -1.0\n","Reward sum: -10.0\n","Position: -0.435, Velocity: 0.005, Action: 2,Reward: -1.0\n","Reward sum: -11.0\n","Position: -0.430, Velocity: 0.005, Action: 2,Reward: -1.0\n","Reward sum: -12.0\n","Position: -0.425, Velocity: 0.006, Action: 2,Reward: -1.0\n","Reward sum: -13.0\n","Position: -0.419, Velocity: 0.006, Action: 2,Reward: -1.0\n","Reward sum: -14.0\n","Position: -0.413, Velocity: 0.006, Action: 2,Reward: -1.0\n","Reward sum: -15.0\n","Position: -0.407, Velocity: 0.006, Action: 2,Reward: -1.0\n","Reward sum: -16.0\n","Position: -0.400, Velocity: 0.006, Action: 2,Reward: -1.0\n","Reward sum: -17.0\n","Position: -0.394, Velocity: 0.006, Action: 2,Reward: -1.0\n","Reward sum: -18.0\n","Position: -0.387, Velocity: 0.007, Action: 2,Reward: -1.0\n","Reward sum: -19.0\n","Position: -0.381, Velocity: 0.007, Action: 2,Reward: -1.0\n","Reward sum: -20.0\n","Position: -0.374, Velocity: 0.006, Action: 2,Reward: -1.0\n","Reward sum: -21.0\n","Position: -0.368, Velocity: 0.006, Action: 2,Reward: -1.0\n","Reward sum: -22.0\n","Position: -0.361, Velocity: 0.006, Action: 2,Reward: -1.0\n","Reward sum: -23.0\n","Position: -0.355, Velocity: 0.006, Action: 2,Reward: -1.0\n","Reward sum: -24.0\n","Position: -0.349, Velocity: 0.006, Action: 2,Reward: -1.0\n","Reward sum: -25.0\n","Position: -0.344, Velocity: 0.006, Action: 2,Reward: -1.0\n","Reward sum: -26.0\n","Position: -0.338, Velocity: 0.005, Action: 2,Reward: -1.0\n","Reward sum: -27.0\n","Position: -0.333, Velocity: 0.005, Action: 2,Reward: -1.0\n","Reward sum: -28.0\n","Position: -0.329, Velocity: 0.005, Action: 2,Reward: -1.0\n","Reward sum: -29.0\n","Position: -0.324, Velocity: 0.004, Action: 2,Reward: -1.0\n","Reward sum: -30.0\n","Position: -0.320, Velocity: 0.004, Action: 2,Reward: -1.0\n","Reward sum: -31.0\n","Position: -0.317, Velocity: 0.003, Action: 2,Reward: -1.0\n","Reward sum: -32.0\n","Position: -0.314, Velocity: 0.003, Action: 2,Reward: -1.0\n","Reward sum: -33.0\n","Position: -0.311, Velocity: 0.003, Action: 2,Reward: -1.0\n","Reward sum: -34.0\n","Position: -0.309, Velocity: 0.002, Action: 2,Reward: -1.0\n","Reward sum: -35.0\n","Position: -0.308, Velocity: 0.002, Action: 2,Reward: -1.0\n","Reward sum: -36.0\n","Position: -0.307, Velocity: 0.001, Action: 2,Reward: -1.0\n","Reward sum: -37.0\n","Position: -0.306, Velocity: 0.001, Action: 2,Reward: -1.0\n","Reward sum: -38.0\n","Position: -0.306, Velocity: 0.000, Action: 2,Reward: -1.0\n","Reward sum: -39.0\n","Position: -0.306, Velocity: -0.000, Action: 0,Reward: -1.0\n","Reward sum: -40.0\n","Position: -0.309, Velocity: -0.003, Action: 0,Reward: -1.0\n","Reward sum: -41.0\n","Position: -0.315, Velocity: -0.006, Action: 0,Reward: -1.0\n","Reward sum: -42.0\n","Position: -0.323, Velocity: -0.008, Action: 0,Reward: -1.0\n","Reward sum: -43.0\n","Position: -0.333, Velocity: -0.010, Action: 0,Reward: -1.0\n","Reward sum: -44.0\n","Position: -0.346, Velocity: -0.013, Action: 0,Reward: -1.0\n","Reward sum: -45.0\n","Position: -0.361, Velocity: -0.015, Action: 0,Reward: -1.0\n","Reward sum: -46.0\n","Position: -0.378, Velocity: -0.017, Action: 0,Reward: -1.0\n","Reward sum: -47.0\n","Position: -0.397, Velocity: -0.019, Action: 0,Reward: -1.0\n","Reward sum: -48.0\n","Position: -0.419, Velocity: -0.021, Action: 0,Reward: -1.0\n","Reward sum: -49.0\n","Position: -0.442, Velocity: -0.023, Action: 0,Reward: -1.0\n","Reward sum: -50.0\n","Position: -0.466, Velocity: -0.025, Action: 0,Reward: -1.0\n","Reward sum: -51.0\n","Position: -0.492, Velocity: -0.026, Action: 0,Reward: -1.0\n","Reward sum: -52.0\n","Position: -0.519, Velocity: -0.027, Action: 0,Reward: -1.0\n","Reward sum: -53.0\n","Position: -0.547, Velocity: -0.028, Action: 0,Reward: -1.0\n","Reward sum: -54.0\n","Position: -0.577, Velocity: -0.029, Action: 0,Reward: -1.0\n","Reward sum: -55.0\n","Position: -0.606, Velocity: -0.030, Action: 0,Reward: -1.0\n","Reward sum: -56.0\n","Position: -0.636, Velocity: -0.030, Action: 0,Reward: -1.0\n","Reward sum: -57.0\n","Position: -0.666, Velocity: -0.030, Action: 0,Reward: -1.0\n","Reward sum: -58.0\n","Position: -0.697, Velocity: -0.030, Action: 0,Reward: -1.0\n","Reward sum: -59.0\n","Position: -0.727, Velocity: -0.030, Action: 0,Reward: -1.0\n","Reward sum: -60.0\n","Position: -0.756, Velocity: -0.030, Action: 0,Reward: -1.0\n","Reward sum: -61.0\n","Position: -0.785, Velocity: -0.029, Action: 0,Reward: -1.0\n","Reward sum: -62.0\n","Position: -0.813, Velocity: -0.028, Action: 0,Reward: -1.0\n","Reward sum: -63.0\n","Position: -0.840, Velocity: -0.027, Action: 0,Reward: -1.0\n","Reward sum: -64.0\n","Position: -0.867, Velocity: -0.026, Action: 0,Reward: -1.0\n","Reward sum: -65.0\n","Position: -0.892, Velocity: -0.025, Action: 0,Reward: -1.0\n","Reward sum: -66.0\n","Position: -0.915, Velocity: -0.024, Action: 0,Reward: -1.0\n","Reward sum: -67.0\n","Position: -0.938, Velocity: -0.023, Action: 0,Reward: -1.0\n","Reward sum: -68.0\n","Position: -0.959, Velocity: -0.021, Action: 0,Reward: -1.0\n","Reward sum: -69.0\n","Position: -0.979, Velocity: -0.020, Action: 0,Reward: -1.0\n","Reward sum: -70.0\n","Position: -0.997, Velocity: -0.018, Action: 0,Reward: -1.0\n","Reward sum: -71.0\n","Position: -1.014, Velocity: -0.017, Action: 0,Reward: -1.0\n","Reward sum: -72.0\n","Position: -1.029, Velocity: -0.015, Action: 0,Reward: -1.0\n","Reward sum: -73.0\n","Position: -1.043, Velocity: -0.014, Action: 0,Reward: -1.0\n","Reward sum: -74.0\n","Position: -1.055, Velocity: -0.012, Action: 0,Reward: -1.0\n","Reward sum: -75.0\n","Position: -1.066, Velocity: -0.011, Action: 0,Reward: -1.0\n","Reward sum: -76.0\n","Position: -1.076, Velocity: -0.009, Action: 0,Reward: -1.0\n","Reward sum: -77.0\n","Position: -1.083, Velocity: -0.008, Action: 0,Reward: -1.0\n","Reward sum: -78.0\n","Position: -1.090, Velocity: -0.006, Action: 0,Reward: -1.0\n","Reward sum: -79.0\n","Position: -1.095, Velocity: -0.005, Action: 0,Reward: -1.0\n","Reward sum: -80.0\n","Position: -1.098, Velocity: -0.003, Action: 0,Reward: -1.0\n","Reward sum: -81.0\n","Position: -1.100, Velocity: -0.002, Action: 0,Reward: -1.0\n","Reward sum: -82.0\n","Position: -1.100, Velocity: -0.000, Action: 0,Reward: -1.0\n","Reward sum: -83.0\n","Position: -1.099, Velocity: 0.001, Action: 2,Reward: -1.0\n","Reward sum: -84.0\n","Position: -1.095, Velocity: 0.004, Action: 2,Reward: -1.0\n","Reward sum: -85.0\n","Position: -1.087, Velocity: 0.008, Action: 2,Reward: -1.0\n","Reward sum: -86.0\n","Position: -1.076, Velocity: 0.011, Action: 2,Reward: -1.0\n","Reward sum: -87.0\n","Position: -1.061, Velocity: 0.015, Action: 2,Reward: -1.0\n","Reward sum: -88.0\n","Position: -1.042, Velocity: 0.018, Action: 2,Reward: -1.0\n","Reward sum: -89.0\n","Position: -1.020, Velocity: 0.022, Action: 2,Reward: -1.0\n","Reward sum: -90.0\n","Position: -0.995, Velocity: 0.025, Action: 2,Reward: -1.0\n","Reward sum: -91.0\n","Position: -0.966, Velocity: 0.029, Action: 2,Reward: -1.0\n","Reward sum: -92.0\n","Position: -0.934, Velocity: 0.032, Action: 2,Reward: -1.0\n","Reward sum: -93.0\n","Position: -0.898, Velocity: 0.036, Action: 2,Reward: -1.0\n","Reward sum: -94.0\n","Position: -0.859, Velocity: 0.039, Action: 2,Reward: -1.0\n","Reward sum: -95.0\n","Position: -0.817, Velocity: 0.042, Action: 2,Reward: -1.0\n","Reward sum: -96.0\n","Position: -0.772, Velocity: 0.045, Action: 2,Reward: -1.0\n","Reward sum: -97.0\n","Position: -0.725, Velocity: 0.048, Action: 2,Reward: -1.0\n","Reward sum: -98.0\n","Position: -0.674, Velocity: 0.050, Action: 2,Reward: -1.0\n","Reward sum: -99.0\n","Position: -0.622, Velocity: 0.052, Action: 2,Reward: -1.0\n","Reward sum: -100.0\n","Position: -0.568, Velocity: 0.054, Action: 2,Reward: -1.0\n","Reward sum: -101.0\n","Position: -0.513, Velocity: 0.055, Action: 2,Reward: -1.0\n","Reward sum: -102.0\n","Position: -0.457, Velocity: 0.056, Action: 2,Reward: -1.0\n","Reward sum: -103.0\n","Position: -0.400, Velocity: 0.057, Action: 2,Reward: -1.0\n","Reward sum: -104.0\n","Position: -0.344, Velocity: 0.057, Action: 2,Reward: -1.0\n","Reward sum: -105.0\n","Position: -0.287, Velocity: 0.056, Action: 2,Reward: -1.0\n","Reward sum: -106.0\n","Position: -0.231, Velocity: 0.056, Action: 2,Reward: -1.0\n","Reward sum: -107.0\n","Position: -0.176, Velocity: 0.055, Action: 2,Reward: -1.0\n","Reward sum: -108.0\n","Position: -0.123, Velocity: 0.054, Action: 2,Reward: -1.0\n","Reward sum: -109.0\n","Position: -0.070, Velocity: 0.052, Action: 2,Reward: -1.0\n","Reward sum: -110.0\n","Position: -0.019, Velocity: 0.051, Action: 2,Reward: -1.0\n","Reward sum: -111.0\n","Position: 0.030, Velocity: 0.049, Action: 2,Reward: -1.0\n","Reward sum: -112.0\n","Position: 0.078, Velocity: 0.048, Action: 2,Reward: -1.0\n","Reward sum: -113.0\n","Position: 0.125, Velocity: 0.047, Action: 2,Reward: -1.0\n","Reward sum: -114.0\n","Position: 0.170, Velocity: 0.045, Action: 2,Reward: -1.0\n","Reward sum: -115.0\n","Position: 0.214, Velocity: 0.044, Action: 2,Reward: -1.0\n","Reward sum: -116.0\n","Position: 0.257, Velocity: 0.043, Action: 2,Reward: -1.0\n","Reward sum: -117.0\n","Position: 0.299, Velocity: 0.042, Action: 2,Reward: -1.0\n","Reward sum: -118.0\n","Position: 0.341, Velocity: 0.042, Action: 2,Reward: -1.0\n","Reward sum: -119.0\n","Position: 0.383, Velocity: 0.041, Action: 2,Reward: -1.0\n","Reward sum: -120.0\n","Position: 0.424, Velocity: 0.041, Action: 2,Reward: -1.0\n","Reward sum: -121.0\n","Position: 0.466, Velocity: 0.042, Action: 2,Reward: -1.0\n","Reward sum: -122.0\n","Episode ended with total reward: -122.0\n"]}],"source":["from time import sleep\n","import gymnasium as gym\n","import random\n","env = gym.make('MountainCar-v0', render_mode='human')\n","\n","seed = 0\n","random.seed(seed)\n","\n","print(f'Action Space: {env.action_space}')\n","print(f'Observation Space: {env.observation_space}')\n","\n","episodes=200\n","reward_sum=0\n","\n","state,_ = env.reset()  # Reset the environment\n","print(state)\n","for episode in range(episodes):\n","    env.render()  # Visualize the environment\n","\n","    position, velocity = state  # Unpack state (position, velocity)\n","\n","    # Improved Policy: Build momentum to the right to reach the top\n","    if velocity < 0:\n","        action = 0  # Push left if velocity is negative\n","    elif velocity >= 0:\n","        action = 2  # Push right to gain momentum\n","\n","    # Taking the action and getting the new state\n","    state, reward, done, truncated, info = env.step(action)\n","    reward_sum += reward\n","\n","    # Environment information\n","    print(f\"Position: {position:.3f}, Velocity: {velocity:.3f}, Action: {action},Reward: {reward}\")\n","    print(f'Reward sum: {reward_sum}')\n","\n","    # Break if the episode is done\n","    if done or truncated:\n","        print(f\"Episode ended with total reward: {reward_sum}\")\n","        break\n","\n","    sleep(0.01)\n","\n","env.close()\n"]},{"cell_type":"markdown","metadata":{"id":"0GjavsnEb79Y"},"source":["An updated policy where the agent:\n","\n","Accelerates to the right when the car is at a low position.\n","Decelerates to the left (or applies less force) when the car is close to the goal to avoid overshooting.\n","i.e Apply a small force or dont accelerate if the car is getting closer to the goal"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xDdeV9bOb79Y","outputId":"008f3a06-8a9e-4040-ab8b-8264e1838d88","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736143963420,"user_tz":-330,"elapsed":13680,"user":{"displayName":"Divya K","userId":"07514915955852652590"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"output_type":"stream","name":"stdout","text":["Action Space: Discrete(3)\n","Observation Space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n","Position: -0.473, Velocity: 0.000, Action: 2, Reward: -1.0\n","Reward sum: -1.0\n","Position: -0.472, Velocity: 0.001, Action: 2, Reward: -1.0\n","Reward sum: -2.0\n","Position: -0.471, Velocity: 0.001, Action: 2, Reward: -1.0\n","Reward sum: -3.0\n","Position: -0.469, Velocity: 0.002, Action: 2, Reward: -1.0\n","Reward sum: -4.0\n","Position: -0.467, Velocity: 0.002, Action: 2, Reward: -1.0\n","Reward sum: -5.0\n","Position: -0.464, Velocity: 0.003, Action: 2, Reward: -1.0\n","Reward sum: -6.0\n","Position: -0.460, Velocity: 0.004, Action: 2, Reward: -1.0\n","Reward sum: -7.0\n","Position: -0.456, Velocity: 0.004, Action: 2, Reward: -1.0\n","Reward sum: -8.0\n","Position: -0.452, Velocity: 0.005, Action: 2, Reward: -1.0\n","Reward sum: -9.0\n","Position: -0.446, Velocity: 0.005, Action: 2, Reward: -1.0\n","Reward sum: -10.0\n","Position: -0.441, Velocity: 0.005, Action: 2, Reward: -1.0\n","Reward sum: -11.0\n","Position: -0.435, Velocity: 0.006, Action: 2, Reward: -1.0\n","Reward sum: -12.0\n","Position: -0.429, Velocity: 0.006, Action: 2, Reward: -1.0\n","Reward sum: -13.0\n","Position: -0.422, Velocity: 0.007, Action: 2, Reward: -1.0\n","Reward sum: -14.0\n","Position: -0.416, Velocity: 0.007, Action: 2, Reward: -1.0\n","Reward sum: -15.0\n","Position: -0.409, Velocity: 0.007, Action: 2, Reward: -1.0\n","Reward sum: -16.0\n","Position: -0.402, Velocity: 0.007, Action: 2, Reward: -1.0\n","Reward sum: -17.0\n","Position: -0.394, Velocity: 0.007, Action: 2, Reward: -1.0\n","Reward sum: -18.0\n","Position: -0.387, Velocity: 0.007, Action: 2, Reward: -1.0\n","Reward sum: -19.0\n","Position: -0.380, Velocity: 0.007, Action: 2, Reward: -1.0\n","Reward sum: -20.0\n","Position: -0.372, Velocity: 0.007, Action: 2, Reward: -1.0\n","Reward sum: -21.0\n","Position: -0.365, Velocity: 0.007, Action: 2, Reward: -1.0\n","Reward sum: -22.0\n","Position: -0.358, Velocity: 0.007, Action: 2, Reward: -1.0\n","Reward sum: -23.0\n","Position: -0.351, Velocity: 0.007, Action: 2, Reward: -1.0\n","Reward sum: -24.0\n","Position: -0.345, Velocity: 0.007, Action: 2, Reward: -1.0\n","Reward sum: -25.0\n","Position: -0.339, Velocity: 0.006, Action: 2, Reward: -1.0\n","Reward sum: -26.0\n","Position: -0.333, Velocity: 0.006, Action: 2, Reward: -1.0\n","Reward sum: -27.0\n","Position: -0.327, Velocity: 0.006, Action: 2, Reward: -1.0\n","Reward sum: -28.0\n","Position: -0.322, Velocity: 0.005, Action: 2, Reward: -1.0\n","Reward sum: -29.0\n","Position: -0.317, Velocity: 0.005, Action: 2, Reward: -1.0\n","Reward sum: -30.0\n","Position: -0.313, Velocity: 0.004, Action: 2, Reward: -1.0\n","Reward sum: -31.0\n","Position: -0.309, Velocity: 0.004, Action: 2, Reward: -1.0\n","Reward sum: -32.0\n","Position: -0.305, Velocity: 0.003, Action: 2, Reward: -1.0\n","Reward sum: -33.0\n","Position: -0.302, Velocity: 0.003, Action: 2, Reward: -1.0\n","Reward sum: -34.0\n","Position: -0.300, Velocity: 0.002, Action: 2, Reward: -1.0\n","Reward sum: -35.0\n","Position: -0.298, Velocity: 0.002, Action: 2, Reward: -1.0\n","Reward sum: -36.0\n","Position: -0.297, Velocity: 0.001, Action: 2, Reward: -1.0\n","Reward sum: -37.0\n","Position: -0.296, Velocity: 0.001, Action: 2, Reward: -1.0\n","Reward sum: -38.0\n","Position: -0.296, Velocity: 0.000, Action: 2, Reward: -1.0\n","Reward sum: -39.0\n","Position: -0.297, Velocity: -0.001, Action: 0, Reward: -1.0\n","Reward sum: -40.0\n","Position: -0.300, Velocity: -0.003, Action: 0, Reward: -1.0\n","Reward sum: -41.0\n","Position: -0.306, Velocity: -0.006, Action: 0, Reward: -1.0\n","Reward sum: -42.0\n","Position: -0.314, Velocity: -0.008, Action: 0, Reward: -1.0\n","Reward sum: -43.0\n","Position: -0.324, Velocity: -0.011, Action: 0, Reward: -1.0\n","Reward sum: -44.0\n","Position: -0.337, Velocity: -0.013, Action: 0, Reward: -1.0\n","Reward sum: -45.0\n","Position: -0.353, Velocity: -0.015, Action: 0, Reward: -1.0\n","Reward sum: -46.0\n","Position: -0.370, Velocity: -0.018, Action: 0, Reward: -1.0\n","Reward sum: -47.0\n","Position: -0.390, Velocity: -0.020, Action: 0, Reward: -1.0\n","Reward sum: -48.0\n","Position: -0.412, Velocity: -0.022, Action: 0, Reward: -1.0\n","Reward sum: -49.0\n","Position: -0.435, Velocity: -0.023, Action: 0, Reward: -1.0\n","Reward sum: -50.0\n","Position: -0.460, Velocity: -0.025, Action: 0, Reward: -1.0\n","Reward sum: -51.0\n","Position: -0.487, Velocity: -0.027, Action: 0, Reward: -1.0\n","Reward sum: -52.0\n","Position: -0.515, Velocity: -0.028, Action: 0, Reward: -1.0\n","Reward sum: -53.0\n","Position: -0.544, Velocity: -0.029, Action: 0, Reward: -1.0\n","Reward sum: -54.0\n","Position: -0.574, Velocity: -0.030, Action: 0, Reward: -1.0\n","Reward sum: -55.0\n","Position: -0.604, Velocity: -0.030, Action: 0, Reward: -1.0\n","Reward sum: -56.0\n","Position: -0.635, Velocity: -0.031, Action: 0, Reward: -1.0\n","Reward sum: -57.0\n","Position: -0.666, Velocity: -0.031, Action: 0, Reward: -1.0\n","Reward sum: -58.0\n","Position: -0.697, Velocity: -0.031, Action: 0, Reward: -1.0\n","Reward sum: -59.0\n","Position: -0.728, Velocity: -0.031, Action: 0, Reward: -1.0\n","Reward sum: -60.0\n","Position: -0.758, Velocity: -0.030, Action: 0, Reward: -1.0\n","Reward sum: -61.0\n","Position: -0.788, Velocity: -0.030, Action: 0, Reward: -1.0\n","Reward sum: -62.0\n","Position: -0.817, Velocity: -0.029, Action: 0, Reward: -1.0\n","Reward sum: -63.0\n","Position: -0.845, Velocity: -0.028, Action: 0, Reward: -1.0\n","Reward sum: -64.0\n","Position: -0.872, Velocity: -0.027, Action: 0, Reward: -1.0\n","Reward sum: -65.0\n","Position: -0.897, Velocity: -0.026, Action: 0, Reward: -1.0\n","Reward sum: -66.0\n","Position: -0.922, Velocity: -0.025, Action: 0, Reward: -1.0\n","Reward sum: -67.0\n","Position: -0.945, Velocity: -0.023, Action: 0, Reward: -1.0\n","Reward sum: -68.0\n","Position: -0.967, Velocity: -0.022, Action: 0, Reward: -1.0\n","Reward sum: -69.0\n","Position: -0.987, Velocity: -0.020, Action: 0, Reward: -1.0\n","Reward sum: -70.0\n","Position: -1.006, Velocity: -0.019, Action: 0, Reward: -1.0\n","Reward sum: -71.0\n","Position: -1.024, Velocity: -0.017, Action: 0, Reward: -1.0\n","Reward sum: -72.0\n","Position: -1.039, Velocity: -0.016, Action: 0, Reward: -1.0\n","Reward sum: -73.0\n","Position: -1.054, Velocity: -0.014, Action: 0, Reward: -1.0\n","Reward sum: -74.0\n","Position: -1.067, Velocity: -0.013, Action: 0, Reward: -1.0\n","Reward sum: -75.0\n","Position: -1.078, Velocity: -0.011, Action: 0, Reward: -1.0\n","Reward sum: -76.0\n","Position: -1.088, Velocity: -0.010, Action: 0, Reward: -1.0\n","Reward sum: -77.0\n","Position: -1.097, Velocity: -0.008, Action: 0, Reward: -1.0\n","Reward sum: -78.0\n","Position: -1.104, Velocity: -0.007, Action: 0, Reward: -1.0\n","Reward sum: -79.0\n","Position: -1.109, Velocity: -0.006, Action: 0, Reward: -1.0\n","Reward sum: -80.0\n","Position: -1.113, Velocity: -0.004, Action: 0, Reward: -1.0\n","Reward sum: -81.0\n","Position: -1.116, Velocity: -0.003, Action: 0, Reward: -1.0\n","Reward sum: -82.0\n","Position: -1.117, Velocity: -0.001, Action: 0, Reward: -1.0\n","Reward sum: -83.0\n","Position: -1.117, Velocity: 0.000, Action: 2, Reward: -1.0\n","Reward sum: -84.0\n","Position: -1.113, Velocity: 0.004, Action: 2, Reward: -1.0\n","Reward sum: -85.0\n","Position: -1.106, Velocity: 0.007, Action: 2, Reward: -1.0\n","Reward sum: -86.0\n","Position: -1.095, Velocity: 0.011, Action: 2, Reward: -1.0\n","Reward sum: -87.0\n","Position: -1.081, Velocity: 0.014, Action: 2, Reward: -1.0\n","Reward sum: -88.0\n","Position: -1.064, Velocity: 0.018, Action: 2, Reward: -1.0\n","Reward sum: -89.0\n","Position: -1.043, Velocity: 0.021, Action: 2, Reward: -1.0\n","Reward sum: -90.0\n","Position: -1.018, Velocity: 0.025, Action: 2, Reward: -1.0\n","Reward sum: -91.0\n","Position: -0.990, Velocity: 0.028, Action: 2, Reward: -1.0\n","Reward sum: -92.0\n","Position: -0.958, Velocity: 0.032, Action: 2, Reward: -1.0\n","Reward sum: -93.0\n","Position: -0.924, Velocity: 0.035, Action: 2, Reward: -1.0\n","Reward sum: -94.0\n","Position: -0.885, Velocity: 0.038, Action: 2, Reward: -1.0\n","Reward sum: -95.0\n","Position: -0.844, Velocity: 0.041, Action: 2, Reward: -1.0\n","Reward sum: -96.0\n","Position: -0.799, Velocity: 0.045, Action: 2, Reward: -1.0\n","Reward sum: -97.0\n","Position: -0.752, Velocity: 0.047, Action: 2, Reward: -1.0\n","Reward sum: -98.0\n","Position: -0.702, Velocity: 0.050, Action: 2, Reward: -1.0\n","Reward sum: -99.0\n","Position: -0.650, Velocity: 0.052, Action: 2, Reward: -1.0\n","Reward sum: -100.0\n","Position: -0.596, Velocity: 0.054, Action: 2, Reward: -1.0\n","Reward sum: -101.0\n","Position: -0.540, Velocity: 0.056, Action: 2, Reward: -1.0\n","Reward sum: -102.0\n","Position: -0.483, Velocity: 0.057, Action: 2, Reward: -1.0\n","Reward sum: -103.0\n","Position: -0.426, Velocity: 0.058, Action: 2, Reward: -1.0\n","Reward sum: -104.0\n","Position: -0.368, Velocity: 0.058, Action: 2, Reward: -1.0\n","Reward sum: -105.0\n","Position: -0.310, Velocity: 0.058, Action: 2, Reward: -1.0\n","Reward sum: -106.0\n","Position: -0.253, Velocity: 0.057, Action: 2, Reward: -1.0\n","Reward sum: -107.0\n","Position: -0.197, Velocity: 0.056, Action: 2, Reward: -1.0\n","Reward sum: -108.0\n","Position: -0.141, Velocity: 0.055, Action: 2, Reward: -1.0\n","Reward sum: -109.0\n","Position: -0.087, Velocity: 0.054, Action: 2, Reward: -1.0\n","Reward sum: -110.0\n","Position: -0.035, Velocity: 0.053, Action: 2, Reward: -1.0\n","Reward sum: -111.0\n","Position: 0.016, Velocity: 0.051, Action: 0, Reward: -1.0\n","Reward sum: -112.0\n","Position: 0.064, Velocity: 0.048, Action: 0, Reward: -1.0\n","Reward sum: -113.0\n","Position: 0.108, Velocity: 0.044, Action: 0, Reward: -1.0\n","Reward sum: -114.0\n","Position: 0.149, Velocity: 0.041, Action: 0, Reward: -1.0\n","Reward sum: -115.0\n","Position: 0.186, Velocity: 0.038, Action: 0, Reward: -1.0\n","Reward sum: -116.0\n","Position: 0.221, Velocity: 0.034, Action: 0, Reward: -1.0\n","Reward sum: -117.0\n","Position: 0.252, Velocity: 0.031, Action: 0, Reward: -1.0\n","Reward sum: -118.0\n","Position: 0.281, Velocity: 0.029, Action: 0, Reward: -1.0\n","Reward sum: -119.0\n","Position: 0.307, Velocity: 0.026, Action: 0, Reward: -1.0\n","Reward sum: -120.0\n","Position: 0.330, Velocity: 0.023, Action: 0, Reward: -1.0\n","Reward sum: -121.0\n","Position: 0.351, Velocity: 0.021, Action: 0, Reward: -1.0\n","Reward sum: -122.0\n","Position: 0.370, Velocity: 0.019, Action: 0, Reward: -1.0\n","Reward sum: -123.0\n","Position: 0.387, Velocity: 0.017, Action: 0, Reward: -1.0\n","Reward sum: -124.0\n","Position: 0.401, Velocity: 0.015, Action: 0, Reward: -1.0\n","Reward sum: -125.0\n","Position: 0.414, Velocity: 0.013, Action: 0, Reward: -1.0\n","Reward sum: -126.0\n","Position: 0.425, Velocity: 0.011, Action: 0, Reward: -1.0\n","Reward sum: -127.0\n","Position: 0.434, Velocity: 0.009, Action: 0, Reward: -1.0\n","Reward sum: -128.0\n","Position: 0.442, Velocity: 0.008, Action: 0, Reward: -1.0\n","Reward sum: -129.0\n","Position: 0.448, Velocity: 0.006, Action: 0, Reward: -1.0\n","Reward sum: -130.0\n","Position: 0.453, Velocity: 0.004, Action: 0, Reward: -1.0\n","Reward sum: -131.0\n","Position: 0.455, Velocity: 0.003, Action: 0, Reward: -1.0\n","Reward sum: -132.0\n","Position: 0.457, Velocity: 0.001, Action: 0, Reward: -1.0\n","Reward sum: -133.0\n","Position: 0.457, Velocity: -0.000, Action: 0, Reward: -1.0\n","Reward sum: -134.0\n","Position: 0.455, Velocity: -0.002, Action: 0, Reward: -1.0\n","Reward sum: -135.0\n","Position: 0.452, Velocity: -0.003, Action: 0, Reward: -1.0\n","Reward sum: -136.0\n","Position: 0.447, Velocity: -0.005, Action: 0, Reward: -1.0\n","Reward sum: -137.0\n","Position: 0.441, Velocity: -0.006, Action: 0, Reward: -1.0\n","Reward sum: -138.0\n","Position: 0.433, Velocity: -0.008, Action: 0, Reward: -1.0\n","Reward sum: -139.0\n","Position: 0.424, Velocity: -0.009, Action: 0, Reward: -1.0\n","Reward sum: -140.0\n","Position: 0.413, Velocity: -0.011, Action: 0, Reward: -1.0\n","Reward sum: -141.0\n","Position: 0.400, Velocity: -0.013, Action: 0, Reward: -1.0\n","Reward sum: -142.0\n","Position: 0.385, Velocity: -0.015, Action: 0, Reward: -1.0\n","Reward sum: -143.0\n","Position: 0.368, Velocity: -0.017, Action: 0, Reward: -1.0\n","Reward sum: -144.0\n","Position: 0.349, Velocity: -0.019, Action: 0, Reward: -1.0\n","Reward sum: -145.0\n","Position: 0.328, Velocity: -0.021, Action: 0, Reward: -1.0\n","Reward sum: -146.0\n","Position: 0.304, Velocity: -0.024, Action: 0, Reward: -1.0\n","Reward sum: -147.0\n","Position: 0.278, Velocity: -0.026, Action: 0, Reward: -1.0\n","Reward sum: -148.0\n","Position: 0.249, Velocity: -0.029, Action: 0, Reward: -1.0\n","Reward sum: -149.0\n","Position: 0.217, Velocity: -0.032, Action: 0, Reward: -1.0\n","Reward sum: -150.0\n","Position: 0.182, Velocity: -0.035, Action: 0, Reward: -1.0\n","Reward sum: -151.0\n","Position: 0.144, Velocity: -0.038, Action: 0, Reward: -1.0\n","Reward sum: -152.0\n","Position: 0.103, Velocity: -0.041, Action: 0, Reward: -1.0\n","Reward sum: -153.0\n","Position: 0.059, Velocity: -0.045, Action: 0, Reward: -1.0\n","Reward sum: -154.0\n","Position: 0.011, Velocity: -0.048, Action: 0, Reward: -1.0\n","Reward sum: -155.0\n","Position: -0.041, Velocity: -0.051, Action: 0, Reward: -1.0\n","Reward sum: -156.0\n","Position: -0.096, Velocity: -0.055, Action: 0, Reward: -1.0\n","Reward sum: -157.0\n","Position: -0.154, Velocity: -0.058, Action: 0, Reward: -1.0\n","Reward sum: -158.0\n","Position: -0.216, Velocity: -0.062, Action: 0, Reward: -1.0\n","Reward sum: -159.0\n","Position: -0.280, Velocity: -0.065, Action: 0, Reward: -1.0\n","Reward sum: -160.0\n","Position: -0.348, Velocity: -0.067, Action: 0, Reward: -1.0\n","Reward sum: -161.0\n","Position: -0.417, Velocity: -0.070, Action: 0, Reward: -1.0\n","Reward sum: -162.0\n","Position: -0.487, Velocity: -0.070, Action: 0, Reward: -1.0\n","Reward sum: -163.0\n","Position: -0.557, Velocity: -0.070, Action: 0, Reward: -1.0\n","Reward sum: -164.0\n","Position: -0.627, Velocity: -0.070, Action: 0, Reward: -1.0\n","Reward sum: -165.0\n","Position: -0.697, Velocity: -0.070, Action: 0, Reward: -1.0\n","Reward sum: -166.0\n","Position: -0.767, Velocity: -0.070, Action: 0, Reward: -1.0\n","Reward sum: -167.0\n","Position: -0.836, Velocity: -0.069, Action: 0, Reward: -1.0\n","Reward sum: -168.0\n","Position: -0.904, Velocity: -0.068, Action: 0, Reward: -1.0\n","Reward sum: -169.0\n","Position: -0.971, Velocity: -0.067, Action: 0, Reward: -1.0\n","Reward sum: -170.0\n","Position: -1.036, Velocity: -0.065, Action: 0, Reward: -1.0\n","Reward sum: -171.0\n","Position: -1.100, Velocity: -0.064, Action: 0, Reward: -1.0\n","Reward sum: -172.0\n","Position: -1.163, Velocity: -0.062, Action: 0, Reward: -1.0\n","Reward sum: -173.0\n","Position: -1.200, Velocity: 0.000, Action: 2, Reward: -1.0\n","Reward sum: -174.0\n","Position: -1.197, Velocity: 0.003, Action: 2, Reward: -1.0\n","Reward sum: -175.0\n","Position: -1.190, Velocity: 0.006, Action: 2, Reward: -1.0\n","Reward sum: -176.0\n","Position: -1.180, Velocity: 0.010, Action: 2, Reward: -1.0\n","Reward sum: -177.0\n","Position: -1.167, Velocity: 0.013, Action: 2, Reward: -1.0\n","Reward sum: -178.0\n","Position: -1.151, Velocity: 0.016, Action: 2, Reward: -1.0\n","Reward sum: -179.0\n","Position: -1.131, Velocity: 0.020, Action: 2, Reward: -1.0\n","Reward sum: -180.0\n","Position: -1.108, Velocity: 0.023, Action: 2, Reward: -1.0\n","Reward sum: -181.0\n","Position: -1.081, Velocity: 0.027, Action: 2, Reward: -1.0\n","Reward sum: -182.0\n","Position: -1.051, Velocity: 0.030, Action: 2, Reward: -1.0\n","Reward sum: -183.0\n","Position: -1.018, Velocity: 0.034, Action: 2, Reward: -1.0\n","Reward sum: -184.0\n","Position: -0.980, Velocity: 0.037, Action: 2, Reward: -1.0\n","Reward sum: -185.0\n","Position: -0.940, Velocity: 0.041, Action: 2, Reward: -1.0\n","Reward sum: -186.0\n","Position: -0.896, Velocity: 0.044, Action: 2, Reward: -1.0\n","Reward sum: -187.0\n","Position: -0.849, Velocity: 0.047, Action: 2, Reward: -1.0\n","Reward sum: -188.0\n","Position: -0.798, Velocity: 0.050, Action: 2, Reward: -1.0\n","Reward sum: -189.0\n","Position: -0.745, Velocity: 0.053, Action: 2, Reward: -1.0\n","Reward sum: -190.0\n","Position: -0.690, Velocity: 0.056, Action: 2, Reward: -1.0\n","Reward sum: -191.0\n","Position: -0.632, Velocity: 0.058, Action: 2, Reward: -1.0\n","Reward sum: -192.0\n","Position: -0.572, Velocity: 0.060, Action: 2, Reward: -1.0\n","Reward sum: -193.0\n","Position: -0.511, Velocity: 0.061, Action: 2, Reward: -1.0\n","Reward sum: -194.0\n","Position: -0.449, Velocity: 0.062, Action: 2, Reward: -1.0\n","Reward sum: -195.0\n","Position: -0.387, Velocity: 0.062, Action: 2, Reward: -1.0\n","Reward sum: -196.0\n","Position: -0.324, Velocity: 0.062, Action: 2, Reward: -1.0\n","Reward sum: -197.0\n","Position: -0.262, Velocity: 0.062, Action: 2, Reward: -1.0\n","Reward sum: -198.0\n","Position: -0.201, Velocity: 0.061, Action: 2, Reward: -1.0\n","Reward sum: -199.0\n","Position: -0.141, Velocity: 0.060, Action: 2, Reward: -1.0\n","Reward sum: -200.0\n","Episode ended with total reward: -200.0\n"]}],"source":["from time import sleep\n","import gymnasium as gym\n","import random\n","env = gym.make('MountainCar-v0', render_mode='human')\n","\n","seed = 0\n","random.seed(seed)\n","\n","print(f'Action Space: {env.action_space}')\n","print(f'Observation Space: {env.observation_space}')\n","\n","episodes=200\n","state,_ = env.reset()  # Reset the environment\n","reward_sum=0\n","\n","for episode in range(episodes):\n","    env.render()  # Visualize the environment\n","\n","    position, velocity = state  # Unpack state (position, velocity)\n","\n","    # Improved Policy: Build momentum to the right to reach the top\n","    if velocity < 0:\n","        action = 0  # Push left if velocity is negative\n","    elif velocity >= 0:\n","        if position < 0:  # Car is in the valley, needs to build momentum\n","            action = 2  # Push right to gain momentum\n","        else:  # Car is getting closer to the goal\n","            action = 0  # No action or apply a small force\n","\n","    # Taking the action and getting the new state\n","    state, reward, done, truncated, info = env.step(action)\n","    reward_sum += reward\n","\n","    # Environment information\n","    print(f\"Position: {position:.3f}, Velocity: {velocity:.3f}, Action: {action}, Reward: {reward}\")\n","    print(f\"Reward sum: {reward_sum}\")\n","\n","    # Break if the episode is done\n","    if done or truncated:\n","        print(f\"Episode ended with total reward: {reward_sum}\")\n","        break\n","\n","    sleep(0.01)\n","\n","env.close()"]},{"cell_type":"markdown","metadata":{"id":"JKWZfhPPb79Y"},"source":["**Additional Exercises**\n","\n","**1.Implement a Custom Environment with Two Cars similar to MountainCar-v0**\n","* Create a custom environment where two cars try to reach the goal (top of the hill) in a MountainCar-like environment. (Use the gym.Env class and inherit it to create our custom environment.)\n","* The environment will have two cars. The state will contain the position and velocity of both cars.\n","* Each car will have 3 actions (move left, move right, or do nothing).\n","* The reward for each car will be -1 for each step until it reaches the goal. If either car reaches the top of the hill, it will receive a reward of +100.\n","* The episode will end if either car reaches the goal.\n","* Test the environment with 5 episodes where random actions are chosen, and the total reward for each episode is printed.\n","\n","**2.Implement a random policy and track the performance in the CartPole-v1 environment.**\n","* Set up the CartPole-v1 environment.\n","* Create a random policy where the action is randomly chosen between 0 and 1.\n","* Run multiple episodes and track the cumulative reward for each episode.\n","* Analyze how random movements perform in balancing the pole.\n","\n","**3. Implement a rule-based policy for the Acrobot-v1 environment.**\n","* Set up the Acrobot-v1 environment.\n","* Implement a policy based on the angle of the two joints of the acrobot:\n","* If the angle of the second joint is less than 0, apply action 1 (move the first joint upward).Otherwise, apply action 0 (move the first joint downward).\n","* Run the policy for several episodes and observe the performance.\n","* Track the rewards and see if you can improve the performance with better rules.\n","    "]},{"cell_type":"markdown","metadata":{"id":"JjZ100m-b79Y"},"source":["Sources / References:\n","\n","1. https://www.gymlibrary.dev/content/environment_creation/\n","2. https://www.gymlibrary.dev/environments/classic_control/cart_pole/\n","3. https://www.gymlibrary.dev/environments/classic_control/acrobot/\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RsgEicqqb79Z"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}